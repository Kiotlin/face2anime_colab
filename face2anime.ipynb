{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "face2anime",
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "1HmOzKvHlZI2INhGhYvcngO2AD8k1bPMi",
      "authorship_tag": "ABX9TyMODGJWESFJUYSZf3oedd1b",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kiotlin/face2anime_colab/blob/master/face2anime.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wExc--voFhMX",
        "colab_type": "text"
      },
      "source": [
        "# 実行環境"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QKbSQJZE9pCV",
        "colab_type": "code",
        "outputId": "cf41d17f-c9e9-4bf6-945e-e461493dd214",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Luj4vBY2iEAf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "b92716ac-ec7f-4ab7-a424-4b81d24f01f1"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tue Feb 18 09:03:28 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.48.02    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   29C    P0    25W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FaLxbGtwAc4f",
        "colab_type": "code",
        "outputId": "053933f1-a72b-44e2-961c-e280a5be5ff8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "source": [
        "!git clone https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix.git"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'pytorch-CycleGAN-and-pix2pix'...\n",
            "remote: Enumerating objects: 5, done.\u001b[K\n",
            "remote: Counting objects: 100% (5/5), done.\u001b[K\n",
            "remote: Compressing objects: 100% (5/5), done.\u001b[K\n",
            "remote: Total 2199 (delta 0), reused 0 (delta 0), pack-reused 2194\u001b[K\n",
            "Receiving objects: 100% (2199/2199), 8.02 MiB | 41.70 MiB/s, done.\n",
            "Resolving deltas: 100% (1424/1424), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvmsWSA7An0v",
        "colab_type": "code",
        "outputId": "3227fbec-bb95-4938-b9ca-9e8a53973175",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 793
        }
      },
      "source": [
        "!pip install torch torchvision\n",
        "!pip install -r pytorch-CycleGAN-and-pix2pix/requirements.txt"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.4.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.5.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.17.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.12.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (6.2.2)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from -r pytorch-CycleGAN-and-pix2pix/requirements.txt (line 1)) (1.4.0)\n",
            "Requirement already satisfied: torchvision>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from -r pytorch-CycleGAN-and-pix2pix/requirements.txt (line 2)) (0.5.0)\n",
            "Collecting dominate>=2.3.1\n",
            "  Downloading https://files.pythonhosted.org/packages/1d/64/593e829416c951eb35c2246430d59b86f640087e29e71f32632bcde5d0f7/dominate-2.4.0-py2.py3-none-any.whl\n",
            "Collecting visdom>=0.1.8.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c9/75/e078f5a2e1df7e0d3044749089fc2823e62d029cc027ed8ae5d71fafcbdc/visdom-0.1.8.9.tar.gz (676kB)\n",
            "\u001b[K     |████████████████████████████████| 686kB 12.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision>=0.2.1->-r pytorch-CycleGAN-and-pix2pix/requirements.txt (line 2)) (1.12.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision>=0.2.1->-r pytorch-CycleGAN-and-pix2pix/requirements.txt (line 2)) (6.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision>=0.2.1->-r pytorch-CycleGAN-and-pix2pix/requirements.txt (line 2)) (1.17.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from visdom>=0.1.8.3->-r pytorch-CycleGAN-and-pix2pix/requirements.txt (line 4)) (1.4.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from visdom>=0.1.8.3->-r pytorch-CycleGAN-and-pix2pix/requirements.txt (line 4)) (2.21.0)\n",
            "Requirement already satisfied: tornado in /usr/local/lib/python3.6/dist-packages (from visdom>=0.1.8.3->-r pytorch-CycleGAN-and-pix2pix/requirements.txt (line 4)) (4.5.3)\n",
            "Requirement already satisfied: pyzmq in /usr/local/lib/python3.6/dist-packages (from visdom>=0.1.8.3->-r pytorch-CycleGAN-and-pix2pix/requirements.txt (line 4)) (17.0.0)\n",
            "Collecting jsonpatch\n",
            "  Downloading https://files.pythonhosted.org/packages/82/53/73ca86f2a680c705dcd1708be4887c559dfe9ed250486dd3ccd8821b8ccb/jsonpatch-1.25-py2.py3-none-any.whl\n",
            "Collecting torchfile\n",
            "  Downloading https://files.pythonhosted.org/packages/91/af/5b305f86f2d218091af657ddb53f984ecbd9518ca9fe8ef4103a007252c9/torchfile-0.1.0.tar.gz\n",
            "Collecting websocket-client\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/5f/f61b420143ed1c8dc69f9eaec5ff1ac36109d52c80de49d66e0c36c3dfdf/websocket_client-0.57.0-py2.py3-none-any.whl (200kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 56.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->visdom>=0.1.8.3->-r pytorch-CycleGAN-and-pix2pix/requirements.txt (line 4)) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->visdom>=0.1.8.3->-r pytorch-CycleGAN-and-pix2pix/requirements.txt (line 4)) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->visdom>=0.1.8.3->-r pytorch-CycleGAN-and-pix2pix/requirements.txt (line 4)) (2019.11.28)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->visdom>=0.1.8.3->-r pytorch-CycleGAN-and-pix2pix/requirements.txt (line 4)) (2.8)\n",
            "Collecting jsonpointer>=1.9\n",
            "  Downloading https://files.pythonhosted.org/packages/18/b0/a80d29577c08eea401659254dfaed87f1af45272899e1812d7e01b679bc5/jsonpointer-2.0-py2.py3-none-any.whl\n",
            "Building wheels for collected packages: visdom, torchfile\n",
            "  Building wheel for visdom (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for visdom: filename=visdom-0.1.8.9-cp36-none-any.whl size=655250 sha256=bd3d80d595c8900e033e8b7e2d6ce079c231aa0e6621f22f56411f9faa5cd731\n",
            "  Stored in directory: /root/.cache/pip/wheels/70/19/a7/6d589ed967f4dfefd33bc166d081257bd4ed0cb618dccfd62a\n",
            "  Building wheel for torchfile (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchfile: filename=torchfile-0.1.0-cp36-none-any.whl size=5712 sha256=db651ae469f49df7033e5091767a3f2038074212d5bac4cffbadc4468b93a70d\n",
            "  Stored in directory: /root/.cache/pip/wheels/b1/c3/d6/9a1cc8f3a99a0fc1124cae20153f36af59a6e683daca0a0814\n",
            "Successfully built visdom torchfile\n",
            "Installing collected packages: dominate, jsonpointer, jsonpatch, torchfile, websocket-client, visdom\n",
            "Successfully installed dominate-2.4.0 jsonpatch-1.25 jsonpointer-2.0 torchfile-0.1.0 visdom-0.1.8.9 websocket-client-0.57.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yN7ujNwkDekY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp -r ./drive/My\\ Drive/Datasets/face2anime_400 ./pytorch-CycleGAN-and-pix2pix/datasets/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLErxHo3QK2-",
        "colab_type": "text"
      },
      "source": [
        "# CycleGAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "etBIJ6urwnXX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.chdir('pytorch-CycleGAN-and-pix2pix/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VCsYzaDw7WC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir face2anime_checkpoints_400"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__32gigPkc0V",
        "colab_type": "code",
        "outputId": "6dbb6f28-623d-4b77-c41f-741b718b7aa7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python train.py --dataroot ./datasets/face2anime_200 --name face2anime_200 --model cycle_gan --checkpoints_dir ./face2anime_checkpoints"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------- Options ---------------\n",
            "               batch_size: 1                             \n",
            "                    beta1: 0.5                           \n",
            "          checkpoints_dir: ./face2anime_checkpoints      \t[default: ./checkpoints]\n",
            "           continue_train: False                         \n",
            "                crop_size: 256                           \n",
            "                 dataroot: ./datasets/face2anime_200     \t[default: None]\n",
            "             dataset_mode: unaligned                     \n",
            "                direction: AtoB                          \n",
            "              display_env: main                          \n",
            "             display_freq: 400                           \n",
            "               display_id: 1                             \n",
            "            display_ncols: 4                             \n",
            "             display_port: 8097                          \n",
            "           display_server: http://localhost              \n",
            "          display_winsize: 256                           \n",
            "                    epoch: latest                        \n",
            "              epoch_count: 1                             \n",
            "                 gan_mode: lsgan                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: True                          \t[default: None]\n",
            "                 lambda_A: 10.0                          \n",
            "                 lambda_B: 10.0                          \n",
            "          lambda_identity: 0.5                           \n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 286                           \n",
            "                       lr: 0.0002                        \n",
            "           lr_decay_iters: 50                            \n",
            "                lr_policy: linear                        \n",
            "         max_dataset_size: inf                           \n",
            "                    model: cycle_gan                     \n",
            "                 n_epochs: 100                           \n",
            "           n_epochs_decay: 100                           \n",
            "               n_layers_D: 3                             \n",
            "                     name: face2anime_200                \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: resnet_9blocks                \n",
            "                      ngf: 64                            \n",
            "               no_dropout: True                          \n",
            "                  no_flip: False                         \n",
            "                  no_html: False                         \n",
            "                     norm: instance                      \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: train                         \n",
            "                pool_size: 50                            \n",
            "               preprocess: resize_and_crop               \n",
            "               print_freq: 100                           \n",
            "             save_by_iter: False                         \n",
            "          save_epoch_freq: 5                             \n",
            "         save_latest_freq: 5000                          \n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "         update_html_freq: 1000                          \n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "dataset [UnalignedDataset] was created\n",
            "The number of training images = 200\n",
            "initialize network with normal\n",
            "initialize network with normal\n",
            "initialize network with normal\n",
            "initialize network with normal\n",
            "model [CycleGANModel] was created\n",
            "---------- Networks initialized -------------\n",
            "[Network G_A] Total number of parameters : 11.378 M\n",
            "[Network G_B] Total number of parameters : 11.378 M\n",
            "[Network D_A] Total number of parameters : 2.765 M\n",
            "[Network D_B] Total number of parameters : 2.765 M\n",
            "-----------------------------------------------\n",
            "Setting up a new session...\n",
            "create web directory ./face2anime_checkpoints/face2anime_200/web...\n",
            "(epoch: 1, iters: 100, time: 0.590, data: 0.218) D_A: 0.249 G_A: 0.345 cycle_A: 3.960 idt_A: 1.134 D_B: 0.358 G_B: 0.310 cycle_B: 2.290 idt_B: 1.992 \n",
            "(epoch: 1, iters: 200, time: 0.564, data: 0.001) D_A: 0.290 G_A: 0.357 cycle_A: 2.308 idt_A: 1.205 D_B: 0.276 G_B: 0.366 cycle_B: 2.651 idt_B: 1.005 \n",
            "End of epoch 1 / 200 \t Time Taken: 108 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 2, iters: 100, time: 0.577, data: 0.230) D_A: 0.239 G_A: 0.416 cycle_A: 2.193 idt_A: 1.168 D_B: 0.285 G_B: 0.449 cycle_B: 2.497 idt_B: 1.042 \n",
            "(epoch: 2, iters: 200, time: 0.941, data: 0.001) D_A: 0.404 G_A: 0.548 cycle_A: 1.277 idt_A: 1.256 D_B: 0.318 G_B: 0.459 cycle_B: 2.699 idt_B: 0.578 \n",
            "End of epoch 2 / 200 \t Time Taken: 107 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 3, iters: 100, time: 0.580, data: 0.176) D_A: 0.242 G_A: 0.578 cycle_A: 1.840 idt_A: 1.128 D_B: 0.111 G_B: 0.304 cycle_B: 2.485 idt_B: 0.903 \n",
            "(epoch: 3, iters: 200, time: 0.572, data: 0.001) D_A: 0.141 G_A: 0.296 cycle_A: 1.043 idt_A: 0.864 D_B: 0.203 G_B: 0.412 cycle_B: 1.701 idt_B: 0.494 \n",
            "End of epoch 3 / 200 \t Time Taken: 107 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 4, iters: 100, time: 0.575, data: 0.176) D_A: 0.172 G_A: 0.626 cycle_A: 3.152 idt_A: 0.877 D_B: 0.204 G_B: 0.396 cycle_B: 1.863 idt_B: 1.468 \n",
            "(epoch: 4, iters: 200, time: 0.972, data: 0.001) D_A: 0.185 G_A: 0.504 cycle_A: 3.021 idt_A: 0.951 D_B: 0.145 G_B: 0.492 cycle_B: 2.229 idt_B: 1.400 \n",
            "End of epoch 4 / 200 \t Time Taken: 108 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 5, iters: 100, time: 0.577, data: 0.175) D_A: 0.304 G_A: 0.715 cycle_A: 1.916 idt_A: 0.784 D_B: 0.170 G_B: 0.256 cycle_B: 1.644 idt_B: 0.978 \n",
            "(epoch: 5, iters: 200, time: 0.568, data: 0.002) D_A: 0.244 G_A: 0.820 cycle_A: 2.519 idt_A: 0.968 D_B: 0.172 G_B: 0.342 cycle_B: 2.114 idt_B: 1.248 \n",
            "saving the model at the end of epoch 5, iters 1000\n",
            "End of epoch 5 / 200 \t Time Taken: 108 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 6, iters: 100, time: 0.572, data: 0.199) D_A: 0.151 G_A: 0.512 cycle_A: 3.307 idt_A: 1.063 D_B: 0.154 G_B: 0.544 cycle_B: 2.620 idt_B: 1.368 \n",
            "(epoch: 6, iters: 200, time: 0.968, data: 0.002) D_A: 0.382 G_A: 0.216 cycle_A: 1.717 idt_A: 1.362 D_B: 0.322 G_B: 0.439 cycle_B: 2.876 idt_B: 0.684 \n",
            "End of epoch 6 / 200 \t Time Taken: 108 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 7, iters: 100, time: 0.570, data: 0.188) D_A: 0.290 G_A: 0.328 cycle_A: 3.231 idt_A: 1.195 D_B: 0.319 G_B: 0.644 cycle_B: 2.563 idt_B: 1.439 \n",
            "(epoch: 7, iters: 200, time: 0.572, data: 0.001) D_A: 0.194 G_A: 0.866 cycle_A: 1.872 idt_A: 0.789 D_B: 0.084 G_B: 0.195 cycle_B: 2.028 idt_B: 0.842 \n",
            "End of epoch 7 / 200 \t Time Taken: 107 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 8, iters: 100, time: 0.577, data: 0.182) D_A: 0.423 G_A: 0.286 cycle_A: 1.957 idt_A: 1.318 D_B: 0.155 G_B: 0.473 cycle_B: 2.384 idt_B: 0.826 \n",
            "(epoch: 8, iters: 200, time: 1.007, data: 0.001) D_A: 0.249 G_A: 0.551 cycle_A: 1.895 idt_A: 0.797 D_B: 0.201 G_B: 0.260 cycle_B: 1.686 idt_B: 0.885 \n",
            "End of epoch 8 / 200 \t Time Taken: 108 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 9, iters: 100, time: 0.572, data: 0.189) D_A: 0.090 G_A: 0.565 cycle_A: 2.082 idt_A: 0.502 D_B: 0.141 G_B: 0.520 cycle_B: 1.228 idt_B: 1.173 \n",
            "(epoch: 9, iters: 200, time: 0.571, data: 0.001) D_A: 0.145 G_A: 0.628 cycle_A: 1.772 idt_A: 0.569 D_B: 0.118 G_B: 0.554 cycle_B: 1.237 idt_B: 0.869 \n",
            "End of epoch 9 / 200 \t Time Taken: 107 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 10, iters: 100, time: 0.570, data: 0.180) D_A: 0.210 G_A: 0.883 cycle_A: 1.911 idt_A: 0.589 D_B: 0.150 G_B: 0.454 cycle_B: 1.358 idt_B: 0.861 \n",
            "(epoch: 10, iters: 200, time: 1.021, data: 0.001) D_A: 0.087 G_A: 0.382 cycle_A: 2.451 idt_A: 0.762 D_B: 0.292 G_B: 0.531 cycle_B: 1.832 idt_B: 0.800 \n",
            "saving the model at the end of epoch 10, iters 2000\n",
            "End of epoch 10 / 200 \t Time Taken: 108 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 11, iters: 100, time: 0.576, data: 0.181) D_A: 0.234 G_A: 0.333 cycle_A: 1.605 idt_A: 0.643 D_B: 0.205 G_B: 0.237 cycle_B: 1.760 idt_B: 0.830 \n",
            "(epoch: 11, iters: 200, time: 0.572, data: 0.001) D_A: 0.071 G_A: 0.105 cycle_A: 2.132 idt_A: 1.208 D_B: 0.243 G_B: 0.998 cycle_B: 2.508 idt_B: 1.053 \n",
            "End of epoch 11 / 200 \t Time Taken: 107 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 12, iters: 100, time: 0.574, data: 0.170) D_A: 0.232 G_A: 0.299 cycle_A: 1.753 idt_A: 1.025 D_B: 0.170 G_B: 0.690 cycle_B: 2.349 idt_B: 1.022 \n",
            "(epoch: 12, iters: 200, time: 1.009, data: 0.001) D_A: 0.208 G_A: 0.586 cycle_A: 3.216 idt_A: 0.772 D_B: 0.303 G_B: 0.341 cycle_B: 1.774 idt_B: 1.312 \n",
            "End of epoch 12 / 200 \t Time Taken: 107 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 13, iters: 100, time: 0.575, data: 0.171) D_A: 0.090 G_A: 0.372 cycle_A: 1.617 idt_A: 0.922 D_B: 0.301 G_B: 0.258 cycle_B: 2.158 idt_B: 0.895 \n",
            "(epoch: 13, iters: 200, time: 0.576, data: 0.001) D_A: 0.123 G_A: 0.732 cycle_A: 2.209 idt_A: 0.572 D_B: 0.113 G_B: 0.929 cycle_B: 1.505 idt_B: 0.849 \n",
            "End of epoch 13 / 200 \t Time Taken: 107 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 14, iters: 100, time: 0.574, data: 0.181) D_A: 0.158 G_A: 0.842 cycle_A: 1.206 idt_A: 0.986 D_B: 0.034 G_B: 0.771 cycle_B: 1.876 idt_B: 0.453 \n",
            "(epoch: 14, iters: 200, time: 1.018, data: 0.001) D_A: 0.259 G_A: 0.359 cycle_A: 1.786 idt_A: 1.487 D_B: 0.582 G_B: 1.657 cycle_B: 3.667 idt_B: 0.748 \n",
            "End of epoch 14 / 200 \t Time Taken: 107 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 15, iters: 100, time: 0.572, data: 0.180) D_A: 0.325 G_A: 0.111 cycle_A: 1.915 idt_A: 0.565 D_B: 0.172 G_B: 0.256 cycle_B: 1.196 idt_B: 0.868 \n",
            "(epoch: 15, iters: 200, time: 0.573, data: 0.001) D_A: 0.223 G_A: 0.428 cycle_A: 1.398 idt_A: 0.777 D_B: 0.176 G_B: 1.058 cycle_B: 1.760 idt_B: 0.680 \n",
            "saving the model at the end of epoch 15, iters 3000\n",
            "End of epoch 15 / 200 \t Time Taken: 108 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 16, iters: 100, time: 0.573, data: 0.170) D_A: 0.115 G_A: 0.781 cycle_A: 1.209 idt_A: 1.348 D_B: 0.095 G_B: 0.143 cycle_B: 2.931 idt_B: 0.837 \n",
            "(epoch: 16, iters: 200, time: 1.063, data: 0.001) D_A: 0.154 G_A: 0.418 cycle_A: 1.288 idt_A: 0.836 D_B: 0.224 G_B: 0.773 cycle_B: 2.311 idt_B: 0.385 \n",
            "End of epoch 16 / 200 \t Time Taken: 108 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 17, iters: 100, time: 0.575, data: 0.164) D_A: 0.192 G_A: 0.693 cycle_A: 2.416 idt_A: 1.091 D_B: 0.169 G_B: 0.347 cycle_B: 2.287 idt_B: 1.124 \n",
            "(epoch: 17, iters: 200, time: 0.572, data: 0.002) D_A: 0.127 G_A: 0.877 cycle_A: 1.440 idt_A: 0.547 D_B: 0.092 G_B: 0.630 cycle_B: 1.251 idt_B: 0.674 \n",
            "End of epoch 17 / 200 \t Time Taken: 107 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 18, iters: 100, time: 0.574, data: 0.189) D_A: 0.114 G_A: 0.868 cycle_A: 2.514 idt_A: 0.968 D_B: 0.387 G_B: 0.377 cycle_B: 2.277 idt_B: 1.071 \n",
            "(epoch: 18, iters: 200, time: 1.069, data: 0.001) D_A: 0.191 G_A: 0.931 cycle_A: 1.327 idt_A: 0.855 D_B: 0.119 G_B: 0.784 cycle_B: 1.400 idt_B: 0.740 \n",
            "End of epoch 18 / 200 \t Time Taken: 108 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 19, iters: 100, time: 0.574, data: 0.164) D_A: 0.157 G_A: 0.296 cycle_A: 1.183 idt_A: 1.273 D_B: 0.420 G_B: 0.663 cycle_B: 3.183 idt_B: 0.871 \n",
            "(epoch: 19, iters: 200, time: 0.576, data: 0.001) D_A: 0.155 G_A: 0.299 cycle_A: 1.733 idt_A: 0.546 D_B: 0.213 G_B: 1.557 cycle_B: 1.256 idt_B: 0.824 \n",
            "End of epoch 19 / 200 \t Time Taken: 107 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 20, iters: 100, time: 0.574, data: 0.190) D_A: 0.175 G_A: 0.978 cycle_A: 1.815 idt_A: 0.751 D_B: 0.041 G_B: 0.397 cycle_B: 1.561 idt_B: 0.638 \n",
            "(epoch: 20, iters: 200, time: 1.109, data: 0.001) D_A: 0.151 G_A: 0.639 cycle_A: 3.449 idt_A: 0.642 D_B: 0.066 G_B: 0.971 cycle_B: 1.432 idt_B: 1.486 \n",
            "saving the model at the end of epoch 20, iters 4000\n",
            "End of epoch 20 / 200 \t Time Taken: 109 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 21, iters: 100, time: 0.581, data: 0.174) D_A: 0.101 G_A: 0.785 cycle_A: 1.210 idt_A: 0.559 D_B: 0.147 G_B: 0.293 cycle_B: 1.140 idt_B: 0.541 \n",
            "(epoch: 21, iters: 200, time: 0.574, data: 0.001) D_A: 0.221 G_A: 0.324 cycle_A: 0.936 idt_A: 0.516 D_B: 0.096 G_B: 1.446 cycle_B: 1.196 idt_B: 0.366 \n",
            "End of epoch 21 / 200 \t Time Taken: 107 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 22, iters: 100, time: 0.571, data: 0.171) D_A: 0.387 G_A: 0.094 cycle_A: 1.788 idt_A: 0.718 D_B: 0.238 G_B: 0.652 cycle_B: 1.529 idt_B: 0.922 \n",
            "(epoch: 22, iters: 200, time: 1.152, data: 0.002) D_A: 0.048 G_A: 0.976 cycle_A: 2.165 idt_A: 0.620 D_B: 0.132 G_B: 0.334 cycle_B: 1.353 idt_B: 1.041 \n",
            "End of epoch 22 / 200 \t Time Taken: 108 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 23, iters: 100, time: 0.572, data: 0.165) D_A: 0.096 G_A: 0.896 cycle_A: 1.824 idt_A: 0.480 D_B: 0.178 G_B: 0.326 cycle_B: 1.008 idt_B: 0.735 \n",
            "(epoch: 23, iters: 200, time: 0.576, data: 0.001) D_A: 0.094 G_A: 0.534 cycle_A: 1.317 idt_A: 1.005 D_B: 0.136 G_B: 0.846 cycle_B: 1.915 idt_B: 0.714 \n",
            "End of epoch 23 / 200 \t Time Taken: 107 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 24, iters: 100, time: 0.574, data: 0.170) D_A: 0.125 G_A: 0.635 cycle_A: 1.680 idt_A: 0.826 D_B: 0.109 G_B: 0.641 cycle_B: 1.695 idt_B: 0.870 \n",
            "(epoch: 24, iters: 200, time: 1.166, data: 0.001) D_A: 0.079 G_A: 0.901 cycle_A: 1.559 idt_A: 0.572 D_B: 0.078 G_B: 0.748 cycle_B: 1.335 idt_B: 0.605 \n",
            "End of epoch 24 / 200 \t Time Taken: 108 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 25, iters: 100, time: 0.580, data: 0.167) D_A: 0.341 G_A: 1.171 cycle_A: 1.135 idt_A: 0.467 D_B: 0.199 G_B: 0.290 cycle_B: 1.176 idt_B: 0.469 \n",
            "(epoch: 25, iters: 200, time: 0.572, data: 0.002) D_A: 0.491 G_A: 0.353 cycle_A: 1.463 idt_A: 0.595 D_B: 0.180 G_B: 0.307 cycle_B: 1.306 idt_B: 0.908 \n",
            "saving the latest model (epoch 25, total_iters 5000)\n",
            "saving the model at the end of epoch 25, iters 5000\n",
            "End of epoch 25 / 200 \t Time Taken: 111 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 26, iters: 100, time: 0.569, data: 0.176) D_A: 0.130 G_A: 0.923 cycle_A: 1.211 idt_A: 0.336 D_B: 0.257 G_B: 0.193 cycle_B: 0.856 idt_B: 0.535 \n",
            "(epoch: 26, iters: 200, time: 1.119, data: 0.002) D_A: 0.155 G_A: 0.482 cycle_A: 1.178 idt_A: 0.687 D_B: 0.226 G_B: 0.172 cycle_B: 1.234 idt_B: 0.615 \n",
            "End of epoch 26 / 200 \t Time Taken: 108 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 27, iters: 100, time: 0.574, data: 0.171) D_A: 0.180 G_A: 0.537 cycle_A: 4.541 idt_A: 0.808 D_B: 0.357 G_B: 0.411 cycle_B: 2.131 idt_B: 1.392 \n",
            "(epoch: 27, iters: 200, time: 0.575, data: 0.001) D_A: 0.201 G_A: 1.007 cycle_A: 1.971 idt_A: 0.862 D_B: 0.197 G_B: 0.479 cycle_B: 1.946 idt_B: 0.889 \n",
            "End of epoch 27 / 200 \t Time Taken: 107 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 28, iters: 100, time: 0.575, data: 0.175) D_A: 0.082 G_A: 0.667 cycle_A: 1.408 idt_A: 0.541 D_B: 0.043 G_B: 1.115 cycle_B: 1.189 idt_B: 0.750 \n",
            "(epoch: 28, iters: 200, time: 1.166, data: 0.001) D_A: 0.214 G_A: 0.702 cycle_A: 1.291 idt_A: 0.714 D_B: 0.262 G_B: 0.144 cycle_B: 1.406 idt_B: 0.934 \n",
            "End of epoch 28 / 200 \t Time Taken: 107 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 29, iters: 100, time: 0.575, data: 0.149) D_A: 0.130 G_A: 0.335 cycle_A: 1.694 idt_A: 0.488 D_B: 0.396 G_B: 0.747 cycle_B: 1.038 idt_B: 0.954 \n",
            "(epoch: 29, iters: 200, time: 0.574, data: 0.002) D_A: 0.282 G_A: 1.205 cycle_A: 2.142 idt_A: 0.523 D_B: 0.026 G_B: 0.416 cycle_B: 1.159 idt_B: 0.933 \n",
            "End of epoch 29 / 200 \t Time Taken: 107 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 30, iters: 100, time: 0.571, data: 0.185) D_A: 0.105 G_A: 0.542 cycle_A: 1.390 idt_A: 0.524 D_B: 0.133 G_B: 0.818 cycle_B: 1.122 idt_B: 0.922 \n",
            "(epoch: 30, iters: 200, time: 1.211, data: 0.001) D_A: 0.096 G_A: 0.549 cycle_A: 1.737 idt_A: 0.352 D_B: 0.126 G_B: 0.483 cycle_B: 0.856 idt_B: 0.887 \n",
            "saving the model at the end of epoch 30, iters 6000\n",
            "End of epoch 30 / 200 \t Time Taken: 109 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 31, iters: 100, time: 0.574, data: 0.162) D_A: 0.199 G_A: 0.284 cycle_A: 2.355 idt_A: 0.650 D_B: 0.250 G_B: 0.271 cycle_B: 1.058 idt_B: 1.177 \n",
            "(epoch: 31, iters: 200, time: 0.573, data: 0.001) D_A: 0.119 G_A: 0.348 cycle_A: 1.824 idt_A: 0.897 D_B: 0.090 G_B: 0.572 cycle_B: 1.660 idt_B: 0.749 \n",
            "End of epoch 31 / 200 \t Time Taken: 107 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 32, iters: 100, time: 0.577, data: 0.183) D_A: 0.156 G_A: 0.570 cycle_A: 1.500 idt_A: 0.647 D_B: 0.078 G_B: 0.664 cycle_B: 1.306 idt_B: 0.533 \n",
            "(epoch: 32, iters: 200, time: 1.185, data: 0.001) D_A: 0.089 G_A: 0.643 cycle_A: 1.174 idt_A: 0.511 D_B: 0.182 G_B: 0.501 cycle_B: 1.268 idt_B: 0.571 \n",
            "End of epoch 32 / 200 \t Time Taken: 108 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 33, iters: 100, time: 0.576, data: 0.161) D_A: 0.168 G_A: 0.663 cycle_A: 2.003 idt_A: 0.906 D_B: 0.071 G_B: 0.516 cycle_B: 2.251 idt_B: 1.008 \n",
            "(epoch: 33, iters: 200, time: 0.577, data: 0.001) D_A: 0.141 G_A: 0.378 cycle_A: 2.421 idt_A: 0.614 D_B: 0.265 G_B: 1.330 cycle_B: 1.079 idt_B: 1.007 \n",
            "End of epoch 33 / 200 \t Time Taken: 107 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 34, iters: 100, time: 0.571, data: 0.162) D_A: 0.315 G_A: 0.359 cycle_A: 1.190 idt_A: 0.608 D_B: 0.226 G_B: 0.479 cycle_B: 1.547 idt_B: 0.423 \n",
            "(epoch: 34, iters: 200, time: 1.275, data: 0.001) D_A: 0.302 G_A: 1.144 cycle_A: 1.308 idt_A: 0.616 D_B: 0.271 G_B: 0.099 cycle_B: 1.400 idt_B: 0.652 \n",
            "End of epoch 34 / 200 \t Time Taken: 108 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 35, iters: 100, time: 0.574, data: 0.172) D_A: 0.202 G_A: 1.216 cycle_A: 2.061 idt_A: 0.899 D_B: 0.107 G_B: 0.569 cycle_B: 2.004 idt_B: 1.061 \n",
            "(epoch: 35, iters: 200, time: 0.574, data: 0.001) D_A: 0.114 G_A: 1.231 cycle_A: 1.849 idt_A: 0.487 D_B: 0.157 G_B: 0.816 cycle_B: 1.621 idt_B: 1.102 \n",
            "saving the model at the end of epoch 35, iters 7000\n",
            "End of epoch 35 / 200 \t Time Taken: 108 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 36, iters: 100, time: 0.576, data: 0.173) D_A: 0.156 G_A: 0.845 cycle_A: 1.425 idt_A: 0.578 D_B: 0.156 G_B: 0.839 cycle_B: 0.919 idt_B: 0.680 \n",
            "(epoch: 36, iters: 200, time: 1.259, data: 0.002) D_A: 0.094 G_A: 1.116 cycle_A: 3.078 idt_A: 0.626 D_B: 0.210 G_B: 0.294 cycle_B: 1.155 idt_B: 0.846 \n",
            "End of epoch 36 / 200 \t Time Taken: 108 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 37, iters: 100, time: 0.575, data: 0.175) D_A: 0.198 G_A: 0.248 cycle_A: 1.141 idt_A: 0.787 D_B: 0.175 G_B: 0.628 cycle_B: 1.494 idt_B: 0.630 \n",
            "(epoch: 37, iters: 200, time: 0.572, data: 0.001) D_A: 0.150 G_A: 0.504 cycle_A: 1.601 idt_A: 0.508 D_B: 0.184 G_B: 0.565 cycle_B: 1.386 idt_B: 0.756 \n",
            "End of epoch 37 / 200 \t Time Taken: 107 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 38, iters: 100, time: 0.573, data: 0.176) D_A: 0.250 G_A: 0.227 cycle_A: 1.676 idt_A: 0.616 D_B: 0.180 G_B: 1.044 cycle_B: 1.515 idt_B: 0.697 \n",
            "(epoch: 38, iters: 200, time: 1.282, data: 0.001) D_A: 0.116 G_A: 0.378 cycle_A: 1.753 idt_A: 0.504 D_B: 0.319 G_B: 0.261 cycle_B: 1.218 idt_B: 0.695 \n",
            "End of epoch 38 / 200 \t Time Taken: 108 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 39, iters: 100, time: 0.577, data: 0.168) D_A: 0.232 G_A: 0.193 cycle_A: 2.417 idt_A: 0.540 D_B: 0.113 G_B: 0.596 cycle_B: 1.410 idt_B: 1.161 \n",
            "(epoch: 39, iters: 200, time: 0.575, data: 0.001) D_A: 0.115 G_A: 0.778 cycle_A: 4.474 idt_A: 0.861 D_B: 0.057 G_B: 0.571 cycle_B: 1.878 idt_B: 2.258 \n",
            "End of epoch 39 / 200 \t Time Taken: 107 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 40, iters: 100, time: 0.573, data: 0.185) D_A: 0.292 G_A: 0.196 cycle_A: 1.043 idt_A: 0.559 D_B: 0.121 G_B: 0.642 cycle_B: 1.625 idt_B: 0.472 \n",
            "(epoch: 40, iters: 200, time: 1.229, data: 0.001) D_A: 0.072 G_A: 0.963 cycle_A: 1.444 idt_A: 0.678 D_B: 0.105 G_B: 0.667 cycle_B: 1.536 idt_B: 0.537 \n",
            "saving the model at the end of epoch 40, iters 8000\n",
            "End of epoch 40 / 200 \t Time Taken: 109 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 41, iters: 100, time: 0.577, data: 0.190) D_A: 0.082 G_A: 0.745 cycle_A: 2.516 idt_A: 0.600 D_B: 0.282 G_B: 0.615 cycle_B: 1.615 idt_B: 1.188 \n",
            "(epoch: 41, iters: 200, time: 0.570, data: 0.001) D_A: 0.098 G_A: 0.444 cycle_A: 1.456 idt_A: 2.067 D_B: 0.122 G_B: 0.946 cycle_B: 4.050 idt_B: 0.594 \n",
            "End of epoch 41 / 200 \t Time Taken: 107 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 42, iters: 100, time: 0.573, data: 0.177) D_A: 0.132 G_A: 0.793 cycle_A: 1.675 idt_A: 0.665 D_B: 0.071 G_B: 0.380 cycle_B: 1.502 idt_B: 0.943 \n",
            "(epoch: 42, iters: 200, time: 1.280, data: 0.001) D_A: 0.038 G_A: 0.733 cycle_A: 1.269 idt_A: 0.511 D_B: 0.057 G_B: 0.530 cycle_B: 1.795 idt_B: 0.464 \n",
            "End of epoch 42 / 200 \t Time Taken: 108 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 43, iters: 100, time: 0.572, data: 0.161) D_A: 0.047 G_A: 0.426 cycle_A: 1.375 idt_A: 1.005 D_B: 0.106 G_B: 0.872 cycle_B: 2.504 idt_B: 0.546 \n",
            "(epoch: 43, iters: 200, time: 0.574, data: 0.001) D_A: 0.150 G_A: 0.165 cycle_A: 2.084 idt_A: 0.561 D_B: 0.067 G_B: 0.816 cycle_B: 1.487 idt_B: 1.009 \n",
            "End of epoch 43 / 200 \t Time Taken: 107 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 44, iters: 100, time: 0.573, data: 0.162) D_A: 0.283 G_A: 0.656 cycle_A: 1.194 idt_A: 0.760 D_B: 0.149 G_B: 0.215 cycle_B: 1.172 idt_B: 0.583 \n",
            "(epoch: 44, iters: 200, time: 1.315, data: 0.002) D_A: 0.048 G_A: 0.379 cycle_A: 1.164 idt_A: 0.898 D_B: 0.295 G_B: 0.236 cycle_B: 2.013 idt_B: 0.518 \n",
            "End of epoch 44 / 200 \t Time Taken: 108 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 45, iters: 100, time: 0.577, data: 0.182) D_A: 0.135 G_A: 0.334 cycle_A: 1.016 idt_A: 0.535 D_B: 0.270 G_B: 0.308 cycle_B: 1.767 idt_B: 0.480 \n",
            "(epoch: 45, iters: 200, time: 0.576, data: 0.001) D_A: 0.069 G_A: 0.733 cycle_A: 1.610 idt_A: 0.694 D_B: 0.128 G_B: 0.291 cycle_B: 1.783 idt_B: 0.587 \n",
            "saving the model at the end of epoch 45, iters 9000\n",
            "End of epoch 45 / 200 \t Time Taken: 108 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 46, iters: 100, time: 0.575, data: 0.236) D_A: 0.027 G_A: 0.497 cycle_A: 1.316 idt_A: 0.502 D_B: 0.118 G_B: 0.511 cycle_B: 1.400 idt_B: 0.639 \n",
            "(epoch: 46, iters: 200, time: 1.413, data: 0.001) D_A: 0.196 G_A: 0.340 cycle_A: 1.107 idt_A: 0.780 D_B: 0.367 G_B: 0.212 cycle_B: 1.631 idt_B: 0.606 \n",
            "End of epoch 46 / 200 \t Time Taken: 108 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 47, iters: 100, time: 0.575, data: 0.177) D_A: 0.161 G_A: 1.020 cycle_A: 2.517 idt_A: 0.666 D_B: 0.369 G_B: 0.086 cycle_B: 1.793 idt_B: 1.190 \n",
            "(epoch: 47, iters: 200, time: 0.576, data: 0.001) D_A: 0.215 G_A: 0.599 cycle_A: 1.356 idt_A: 0.538 D_B: 0.172 G_B: 0.234 cycle_B: 1.352 idt_B: 0.666 \n",
            "End of epoch 47 / 200 \t Time Taken: 107 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 48, iters: 100, time: 0.569, data: 0.163) D_A: 0.083 G_A: 0.803 cycle_A: 1.487 idt_A: 0.551 D_B: 0.110 G_B: 0.442 cycle_B: 1.197 idt_B: 0.757 \n",
            "(epoch: 48, iters: 200, time: 1.392, data: 0.001) D_A: 0.338 G_A: 1.284 cycle_A: 1.425 idt_A: 0.430 D_B: 0.299 G_B: 0.162 cycle_B: 1.202 idt_B: 0.678 \n",
            "End of epoch 48 / 200 \t Time Taken: 108 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 49, iters: 100, time: 0.576, data: 0.197) D_A: 0.067 G_A: 1.037 cycle_A: 1.974 idt_A: 0.682 D_B: 0.093 G_B: 0.518 cycle_B: 1.548 idt_B: 0.740 \n",
            "(epoch: 49, iters: 200, time: 0.574, data: 0.001) D_A: 0.221 G_A: 0.462 cycle_A: 1.299 idt_A: 0.498 D_B: 0.263 G_B: 0.800 cycle_B: 1.095 idt_B: 0.462 \n",
            "End of epoch 49 / 200 \t Time Taken: 107 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 50, iters: 100, time: 0.575, data: 0.173) D_A: 0.110 G_A: 0.697 cycle_A: 1.753 idt_A: 0.564 D_B: 0.268 G_B: 0.189 cycle_B: 1.528 idt_B: 0.872 \n",
            "(epoch: 50, iters: 200, time: 1.318, data: 0.004) D_A: 0.038 G_A: 0.265 cycle_A: 1.387 idt_A: 0.643 D_B: 0.044 G_B: 0.664 cycle_B: 1.435 idt_B: 0.665 \n",
            "saving the latest model (epoch 50, total_iters 10000)\n",
            "saving the model at the end of epoch 50, iters 10000\n",
            "End of epoch 50 / 200 \t Time Taken: 111 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 51, iters: 100, time: 0.574, data: 0.166) D_A: 0.139 G_A: 0.247 cycle_A: 1.343 idt_A: 0.641 D_B: 0.058 G_B: 0.504 cycle_B: 1.744 idt_B: 0.588 \n",
            "(epoch: 51, iters: 200, time: 0.579, data: 0.002) D_A: 0.187 G_A: 1.057 cycle_A: 3.124 idt_A: 0.690 D_B: 0.201 G_B: 0.386 cycle_B: 1.385 idt_B: 0.813 \n",
            "End of epoch 51 / 200 \t Time Taken: 107 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 52, iters: 100, time: 0.575, data: 0.172) D_A: 0.300 G_A: 0.723 cycle_A: 1.769 idt_A: 0.493 D_B: 0.227 G_B: 0.816 cycle_B: 1.302 idt_B: 0.833 \n",
            "(epoch: 52, iters: 200, time: 1.483, data: 0.001) D_A: 0.260 G_A: 0.054 cycle_A: 1.360 idt_A: 0.495 D_B: 0.344 G_B: 1.095 cycle_B: 1.220 idt_B: 0.580 \n",
            "End of epoch 52 / 200 \t Time Taken: 108 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 53, iters: 100, time: 0.576, data: 0.179) D_A: 0.023 G_A: 0.856 cycle_A: 2.564 idt_A: 0.647 D_B: 0.447 G_B: 1.115 cycle_B: 1.558 idt_B: 1.130 \n",
            "(epoch: 53, iters: 200, time: 0.573, data: 0.001) D_A: 0.112 G_A: 0.459 cycle_A: 1.199 idt_A: 0.551 D_B: 0.070 G_B: 0.208 cycle_B: 1.372 idt_B: 0.719 \n",
            "End of epoch 53 / 200 \t Time Taken: 107 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 54, iters: 100, time: 0.576, data: 0.247) D_A: 0.147 G_A: 0.578 cycle_A: 2.012 idt_A: 0.456 D_B: 0.355 G_B: 0.193 cycle_B: 1.252 idt_B: 0.936 \n",
            "(epoch: 54, iters: 200, time: 1.389, data: 0.001) D_A: 0.090 G_A: 0.443 cycle_A: 0.825 idt_A: 0.881 D_B: 0.139 G_B: 0.562 cycle_B: 1.692 idt_B: 0.616 \n",
            "End of epoch 54 / 200 \t Time Taken: 108 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 55, iters: 100, time: 0.579, data: 0.178) D_A: 0.085 G_A: 1.007 cycle_A: 1.332 idt_A: 0.487 D_B: 0.197 G_B: 0.799 cycle_B: 1.162 idt_B: 0.644 \n",
            "(epoch: 55, iters: 200, time: 0.575, data: 0.001) D_A: 0.237 G_A: 1.745 cycle_A: 1.483 idt_A: 0.456 D_B: 0.330 G_B: 0.754 cycle_B: 1.092 idt_B: 0.549 \n",
            "saving the model at the end of epoch 55, iters 11000\n",
            "End of epoch 55 / 200 \t Time Taken: 108 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 56, iters: 100, time: 0.573, data: 0.191) D_A: 0.188 G_A: 0.824 cycle_A: 1.074 idt_A: 0.512 D_B: 0.106 G_B: 0.366 cycle_B: 1.068 idt_B: 0.445 \n",
            "(epoch: 56, iters: 200, time: 1.377, data: 0.001) D_A: 0.111 G_A: 0.602 cycle_A: 1.323 idt_A: 0.444 D_B: 0.611 G_B: 0.080 cycle_B: 1.083 idt_B: 0.520 \n",
            "End of epoch 56 / 200 \t Time Taken: 108 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 57, iters: 100, time: 0.575, data: 0.174) D_A: 0.130 G_A: 0.620 cycle_A: 1.222 idt_A: 0.674 D_B: 0.076 G_B: 0.822 cycle_B: 1.372 idt_B: 0.684 \n",
            "(epoch: 57, iters: 200, time: 0.574, data: 0.001) D_A: 0.058 G_A: 0.717 cycle_A: 1.466 idt_A: 0.480 D_B: 0.190 G_B: 0.371 cycle_B: 1.562 idt_B: 0.645 \n",
            "End of epoch 57 / 200 \t Time Taken: 107 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 58, iters: 100, time: 0.574, data: 0.181) D_A: 0.102 G_A: 1.192 cycle_A: 1.585 idt_A: 0.497 D_B: 0.127 G_B: 0.751 cycle_B: 1.647 idt_B: 0.600 \n",
            "(epoch: 58, iters: 200, time: 1.367, data: 0.001) D_A: 0.099 G_A: 0.414 cycle_A: 1.022 idt_A: 0.535 D_B: 0.422 G_B: 0.082 cycle_B: 1.582 idt_B: 0.450 \n",
            "End of epoch 58 / 200 \t Time Taken: 108 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 59, iters: 100, time: 0.565, data: 0.159) D_A: 0.121 G_A: 1.039 cycle_A: 1.254 idt_A: 0.555 D_B: 0.183 G_B: 0.442 cycle_B: 1.279 idt_B: 0.563 \n",
            "(epoch: 59, iters: 200, time: 0.573, data: 0.001) D_A: 0.176 G_A: 0.756 cycle_A: 1.975 idt_A: 0.547 D_B: 0.081 G_B: 0.731 cycle_B: 1.251 idt_B: 0.788 \n",
            "End of epoch 59 / 200 \t Time Taken: 107 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 60, iters: 100, time: 0.571, data: 0.186) D_A: 0.166 G_A: 0.311 cycle_A: 2.818 idt_A: 0.508 D_B: 0.054 G_B: 0.795 cycle_B: 1.101 idt_B: 1.951 \n",
            "(epoch: 60, iters: 200, time: 1.466, data: 0.001) D_A: 0.122 G_A: 0.742 cycle_A: 1.574 idt_A: 0.717 D_B: 0.083 G_B: 0.714 cycle_B: 1.983 idt_B: 0.683 \n",
            "saving the model at the end of epoch 60, iters 12000\n",
            "End of epoch 60 / 200 \t Time Taken: 109 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 61, iters: 100, time: 0.576, data: 0.191) D_A: 0.285 G_A: 1.361 cycle_A: 1.171 idt_A: 0.686 D_B: 0.105 G_B: 0.515 cycle_B: 1.204 idt_B: 0.467 \n",
            "(epoch: 61, iters: 200, time: 0.574, data: 0.001) D_A: 0.355 G_A: 0.097 cycle_A: 1.076 idt_A: 0.431 D_B: 0.389 G_B: 0.240 cycle_B: 1.360 idt_B: 0.528 \n",
            "End of epoch 61 / 200 \t Time Taken: 107 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 62, iters: 100, time: 0.576, data: 0.144) D_A: 0.095 G_A: 0.605 cycle_A: 1.990 idt_A: 0.570 D_B: 0.241 G_B: 0.336 cycle_B: 1.773 idt_B: 0.924 \n",
            "(epoch: 62, iters: 200, time: 1.434, data: 0.001) D_A: 0.138 G_A: 0.384 cycle_A: 1.498 idt_A: 0.347 D_B: 0.108 G_B: 0.460 cycle_B: 0.780 idt_B: 0.442 \n",
            "End of epoch 62 / 200 \t Time Taken: 108 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 63, iters: 100, time: 0.576, data: 0.194) D_A: 0.119 G_A: 0.942 cycle_A: 1.620 idt_A: 1.026 D_B: 0.327 G_B: 0.524 cycle_B: 2.649 idt_B: 0.880 \n",
            "(epoch: 63, iters: 200, time: 0.576, data: 0.002) D_A: 0.219 G_A: 0.394 cycle_A: 1.651 idt_A: 0.703 D_B: 0.375 G_B: 0.584 cycle_B: 1.524 idt_B: 0.641 \n",
            "End of epoch 63 / 200 \t Time Taken: 107 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 64, iters: 100, time: 0.573, data: 0.175) D_A: 0.102 G_A: 0.515 cycle_A: 0.986 idt_A: 0.474 D_B: 0.161 G_B: 0.167 cycle_B: 1.332 idt_B: 0.488 \n",
            "(epoch: 64, iters: 200, time: 1.445, data: 0.001) D_A: 0.251 G_A: 0.161 cycle_A: 1.208 idt_A: 0.517 D_B: 0.229 G_B: 0.362 cycle_B: 1.138 idt_B: 0.461 \n",
            "End of epoch 64 / 200 \t Time Taken: 108 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 65, iters: 100, time: 0.575, data: 0.190) D_A: 0.065 G_A: 0.766 cycle_A: 1.121 idt_A: 0.709 D_B: 0.276 G_B: 0.820 cycle_B: 1.672 idt_B: 0.466 \n",
            "(epoch: 65, iters: 200, time: 0.577, data: 0.001) D_A: 0.583 G_A: 0.059 cycle_A: 2.679 idt_A: 0.497 D_B: 0.046 G_B: 0.266 cycle_B: 1.183 idt_B: 1.421 \n",
            "saving the model at the end of epoch 65, iters 13000\n",
            "End of epoch 65 / 200 \t Time Taken: 108 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 66, iters: 100, time: 0.571, data: 0.206) D_A: 0.089 G_A: 0.571 cycle_A: 1.182 idt_A: 0.419 D_B: 0.274 G_B: 0.748 cycle_B: 1.097 idt_B: 0.608 \n",
            "(epoch: 66, iters: 200, time: 1.460, data: 0.001) D_A: 0.101 G_A: 0.188 cycle_A: 1.471 idt_A: 0.446 D_B: 0.083 G_B: 0.502 cycle_B: 0.801 idt_B: 0.642 \n",
            "End of epoch 66 / 200 \t Time Taken: 108 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 67, iters: 100, time: 0.577, data: 0.180) D_A: 0.037 G_A: 1.249 cycle_A: 1.396 idt_A: 0.448 D_B: 0.115 G_B: 0.546 cycle_B: 1.234 idt_B: 0.787 \n",
            "(epoch: 67, iters: 200, time: 0.576, data: 0.001) D_A: 0.168 G_A: 0.515 cycle_A: 0.972 idt_A: 0.476 D_B: 0.082 G_B: 0.588 cycle_B: 1.253 idt_B: 0.381 \n",
            "End of epoch 67 / 200 \t Time Taken: 107 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 68, iters: 100, time: 0.576, data: 0.171) D_A: 0.057 G_A: 0.331 cycle_A: 1.965 idt_A: 0.734 D_B: 0.224 G_B: 0.631 cycle_B: 1.778 idt_B: 1.028 \n",
            "(epoch: 68, iters: 200, time: 1.534, data: 0.002) D_A: 0.106 G_A: 0.501 cycle_A: 1.310 idt_A: 0.579 D_B: 0.254 G_B: 0.432 cycle_B: 1.388 idt_B: 0.423 \n",
            "End of epoch 68 / 200 \t Time Taken: 108 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 69, iters: 100, time: 0.574, data: 0.185) D_A: 0.118 G_A: 0.512 cycle_A: 1.300 idt_A: 0.565 D_B: 0.156 G_B: 0.723 cycle_B: 1.535 idt_B: 0.501 \n",
            "(epoch: 69, iters: 200, time: 0.570, data: 0.001) D_A: 0.268 G_A: 0.811 cycle_A: 2.309 idt_A: 0.442 D_B: 0.059 G_B: 0.717 cycle_B: 0.759 idt_B: 0.731 \n",
            "End of epoch 69 / 200 \t Time Taken: 107 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 70, iters: 100, time: 0.571, data: 0.203) D_A: 0.164 G_A: 0.603 cycle_A: 1.720 idt_A: 0.320 D_B: 0.227 G_B: 0.790 cycle_B: 0.909 idt_B: 0.748 \n",
            "(epoch: 70, iters: 200, time: 1.612, data: 0.001) D_A: 0.110 G_A: 0.528 cycle_A: 1.576 idt_A: 0.351 D_B: 0.199 G_B: 0.181 cycle_B: 0.926 idt_B: 0.708 \n",
            "saving the model at the end of epoch 70, iters 14000\n",
            "End of epoch 70 / 200 \t Time Taken: 109 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 71, iters: 100, time: 0.573, data: 0.232) D_A: 0.197 G_A: 0.788 cycle_A: 1.542 idt_A: 0.784 D_B: 0.335 G_B: 0.747 cycle_B: 1.530 idt_B: 0.618 \n",
            "(epoch: 71, iters: 200, time: 0.576, data: 0.001) D_A: 0.195 G_A: 0.267 cycle_A: 2.175 idt_A: 0.440 D_B: 0.325 G_B: 1.122 cycle_B: 1.208 idt_B: 0.840 \n",
            "End of epoch 71 / 200 \t Time Taken: 108 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 72, iters: 100, time: 0.574, data: 0.188) D_A: 0.085 G_A: 0.454 cycle_A: 1.261 idt_A: 0.559 D_B: 0.413 G_B: 0.954 cycle_B: 1.645 idt_B: 0.598 \n",
            "(epoch: 72, iters: 200, time: 1.652, data: 0.001) D_A: 0.086 G_A: 0.695 cycle_A: 1.167 idt_A: 0.520 D_B: 0.217 G_B: 0.616 cycle_B: 1.336 idt_B: 0.434 \n",
            "End of epoch 72 / 200 \t Time Taken: 108 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 73, iters: 100, time: 0.571, data: 0.182) D_A: 0.145 G_A: 1.177 cycle_A: 1.336 idt_A: 0.446 D_B: 0.270 G_B: 0.932 cycle_B: 1.248 idt_B: 0.711 \n",
            "(epoch: 73, iters: 200, time: 0.574, data: 0.002) D_A: 0.106 G_A: 0.538 cycle_A: 1.154 idt_A: 0.387 D_B: 0.045 G_B: 0.686 cycle_B: 1.159 idt_B: 0.429 \n",
            "End of epoch 73 / 200 \t Time Taken: 107 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 74, iters: 100, time: 0.578, data: 0.185) D_A: 0.032 G_A: 0.550 cycle_A: 1.164 idt_A: 0.396 D_B: 0.228 G_B: 0.349 cycle_B: 0.930 idt_B: 0.506 \n",
            "(epoch: 74, iters: 200, time: 1.715, data: 0.001) D_A: 0.212 G_A: 0.391 cycle_A: 1.705 idt_A: 0.861 D_B: 0.459 G_B: 0.802 cycle_B: 2.257 idt_B: 0.498 \n",
            "End of epoch 74 / 200 \t Time Taken: 109 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 75, iters: 100, time: 0.577, data: 0.191) D_A: 0.066 G_A: 0.195 cycle_A: 1.022 idt_A: 0.425 D_B: 0.168 G_B: 1.558 cycle_B: 1.220 idt_B: 0.437 \n",
            "(epoch: 75, iters: 200, time: 0.575, data: 0.001) D_A: 0.261 G_A: 0.369 cycle_A: 1.166 idt_A: 0.554 D_B: 0.614 G_B: 0.060 cycle_B: 1.476 idt_B: 0.559 \n",
            "saving the latest model (epoch 75, total_iters 15000)\n",
            "saving the model at the end of epoch 75, iters 15000\n",
            "End of epoch 75 / 200 \t Time Taken: 111 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 76, iters: 100, time: 0.572, data: 0.227) D_A: 0.061 G_A: 0.776 cycle_A: 1.871 idt_A: 0.553 D_B: 0.236 G_B: 0.664 cycle_B: 1.097 idt_B: 0.870 \n",
            "(epoch: 76, iters: 200, time: 1.695, data: 0.001) D_A: 0.166 G_A: 0.788 cycle_A: 1.064 idt_A: 0.397 D_B: 0.154 G_B: 0.290 cycle_B: 1.084 idt_B: 0.369 \n",
            "End of epoch 76 / 200 \t Time Taken: 108 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 77, iters: 100, time: 0.576, data: 0.179) D_A: 0.132 G_A: 0.078 cycle_A: 1.809 idt_A: 0.730 D_B: 0.143 G_B: 0.530 cycle_B: 1.287 idt_B: 0.591 \n",
            "(epoch: 77, iters: 200, time: 0.575, data: 0.002) D_A: 0.168 G_A: 0.715 cycle_A: 1.282 idt_A: 0.494 D_B: 0.282 G_B: 0.250 cycle_B: 1.126 idt_B: 0.431 \n",
            "End of epoch 77 / 200 \t Time Taken: 107 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 78, iters: 100, time: 0.572, data: 0.184) D_A: 0.078 G_A: 0.474 cycle_A: 1.062 idt_A: 0.597 D_B: 0.238 G_B: 0.439 cycle_B: 1.518 idt_B: 0.392 \n",
            "(epoch: 78, iters: 200, time: 1.629, data: 0.002) D_A: 0.105 G_A: 1.161 cycle_A: 1.612 idt_A: 0.509 D_B: 0.103 G_B: 0.459 cycle_B: 1.477 idt_B: 0.870 \n",
            "End of epoch 78 / 200 \t Time Taken: 108 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 79, iters: 100, time: 0.576, data: 0.194) D_A: 0.052 G_A: 0.173 cycle_A: 1.631 idt_A: 0.455 D_B: 0.156 G_B: 0.467 cycle_B: 0.921 idt_B: 0.653 \n",
            "(epoch: 79, iters: 200, time: 0.576, data: 0.001) D_A: 0.077 G_A: 1.036 cycle_A: 1.007 idt_A: 0.624 D_B: 0.156 G_B: 0.370 cycle_B: 1.752 idt_B: 0.353 \n",
            "End of epoch 79 / 200 \t Time Taken: 107 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 80, iters: 100, time: 0.574, data: 0.190) D_A: 0.054 G_A: 1.175 cycle_A: 1.547 idt_A: 0.437 D_B: 0.208 G_B: 0.591 cycle_B: 1.306 idt_B: 0.670 \n",
            "(epoch: 80, iters: 200, time: 1.687, data: 0.001) D_A: 0.179 G_A: 0.875 cycle_A: 0.976 idt_A: 0.393 D_B: 0.185 G_B: 0.263 cycle_B: 1.255 idt_B: 0.277 \n",
            "saving the model at the end of epoch 80, iters 16000\n",
            "End of epoch 80 / 200 \t Time Taken: 109 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 81, iters: 100, time: 0.576, data: 0.222) D_A: 0.149 G_A: 0.440 cycle_A: 1.088 idt_A: 0.445 D_B: 0.223 G_B: 0.537 cycle_B: 1.109 idt_B: 0.396 \n",
            "(epoch: 81, iters: 200, time: 0.571, data: 0.002) D_A: 0.211 G_A: 0.292 cycle_A: 1.261 idt_A: 0.347 D_B: 0.200 G_B: 0.296 cycle_B: 0.977 idt_B: 0.466 \n",
            "End of epoch 81 / 200 \t Time Taken: 107 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 82, iters: 100, time: 0.571, data: 0.175) D_A: 0.320 G_A: 0.925 cycle_A: 0.943 idt_A: 0.736 D_B: 0.245 G_B: 0.460 cycle_B: 1.672 idt_B: 0.315 \n",
            "(epoch: 82, iters: 200, time: 1.664, data: 0.002) D_A: 0.092 G_A: 0.598 cycle_A: 1.400 idt_A: 0.821 D_B: 0.257 G_B: 0.272 cycle_B: 2.042 idt_B: 0.566 \n",
            "End of epoch 82 / 200 \t Time Taken: 108 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 83, iters: 100, time: 0.571, data: 0.171) D_A: 0.128 G_A: 0.881 cycle_A: 1.193 idt_A: 0.506 D_B: 0.220 G_B: 0.272 cycle_B: 1.268 idt_B: 0.379 \n",
            "(epoch: 83, iters: 200, time: 0.572, data: 0.001) D_A: 0.109 G_A: 0.566 cycle_A: 1.573 idt_A: 0.708 D_B: 0.062 G_B: 0.305 cycle_B: 1.243 idt_B: 0.805 \n",
            "End of epoch 83 / 200 \t Time Taken: 107 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 84, iters: 100, time: 0.572, data: 0.164) D_A: 0.117 G_A: 1.285 cycle_A: 1.050 idt_A: 0.499 D_B: 0.194 G_B: 0.424 cycle_B: 1.254 idt_B: 0.371 \n",
            "(epoch: 84, iters: 200, time: 1.747, data: 0.001) D_A: 0.099 G_A: 0.279 cycle_A: 0.921 idt_A: 0.794 D_B: 0.166 G_B: 0.290 cycle_B: 1.765 idt_B: 0.301 \n",
            "End of epoch 84 / 200 \t Time Taken: 108 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 85, iters: 100, time: 0.579, data: 0.205) D_A: 0.070 G_A: 0.857 cycle_A: 1.524 idt_A: 0.423 D_B: 0.076 G_B: 0.774 cycle_B: 1.304 idt_B: 0.590 \n",
            "(epoch: 85, iters: 200, time: 0.571, data: 0.001) D_A: 0.101 G_A: 0.787 cycle_A: 1.363 idt_A: 0.346 D_B: 0.094 G_B: 0.255 cycle_B: 1.101 idt_B: 0.428 \n",
            "saving the model at the end of epoch 85, iters 17000\n",
            "End of epoch 85 / 200 \t Time Taken: 108 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 86, iters: 100, time: 0.573, data: 0.181) D_A: 0.079 G_A: 0.515 cycle_A: 1.042 idt_A: 0.875 D_B: 0.103 G_B: 0.387 cycle_B: 1.603 idt_B: 0.620 \n",
            "(epoch: 86, iters: 200, time: 1.769, data: 0.001) D_A: 0.197 G_A: 0.355 cycle_A: 1.124 idt_A: 0.500 D_B: 0.416 G_B: 0.536 cycle_B: 1.226 idt_B: 0.433 \n",
            "End of epoch 86 / 200 \t Time Taken: 108 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 87, iters: 100, time: 0.577, data: 0.166) D_A: 0.143 G_A: 0.964 cycle_A: 1.752 idt_A: 0.512 D_B: 0.184 G_B: 0.820 cycle_B: 1.039 idt_B: 0.663 \n",
            "(epoch: 87, iters: 200, time: 0.577, data: 0.002) D_A: 0.346 G_A: 0.350 cycle_A: 2.535 idt_A: 0.609 D_B: 0.165 G_B: 0.538 cycle_B: 1.867 idt_B: 0.802 \n",
            "End of epoch 87 / 200 \t Time Taken: 107 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 88, iters: 100, time: 0.573, data: 0.168) D_A: 0.077 G_A: 0.572 cycle_A: 0.986 idt_A: 0.844 D_B: 0.104 G_B: 0.755 cycle_B: 1.694 idt_B: 0.315 \n",
            "(epoch: 88, iters: 200, time: 1.690, data: 0.001) D_A: 0.208 G_A: 0.332 cycle_A: 2.014 idt_A: 0.370 D_B: 0.182 G_B: 1.003 cycle_B: 0.951 idt_B: 1.165 \n",
            "End of epoch 88 / 200 \t Time Taken: 108 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 89, iters: 100, time: 0.576, data: 0.190) D_A: 0.198 G_A: 0.446 cycle_A: 1.389 idt_A: 0.576 D_B: 0.069 G_B: 0.385 cycle_B: 1.700 idt_B: 0.477 \n",
            "(epoch: 89, iters: 200, time: 0.575, data: 0.002) D_A: 0.110 G_A: 0.578 cycle_A: 1.193 idt_A: 0.459 D_B: 0.179 G_B: 0.382 cycle_B: 1.165 idt_B: 0.795 \n",
            "End of epoch 89 / 200 \t Time Taken: 107 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 90, iters: 100, time: 0.574, data: 0.158) D_A: 0.091 G_A: 0.892 cycle_A: 1.015 idt_A: 0.471 D_B: 0.159 G_B: 0.367 cycle_B: 1.238 idt_B: 0.582 \n",
            "(epoch: 90, iters: 200, time: 1.733, data: 0.002) D_A: 0.127 G_A: 0.383 cycle_A: 1.354 idt_A: 0.662 D_B: 0.085 G_B: 0.494 cycle_B: 1.328 idt_B: 0.719 \n",
            "saving the model at the end of epoch 90, iters 18000\n",
            "End of epoch 90 / 200 \t Time Taken: 109 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 91, iters: 100, time: 0.579, data: 0.209) D_A: 0.172 G_A: 0.259 cycle_A: 1.494 idt_A: 0.551 D_B: 0.151 G_B: 0.408 cycle_B: 1.688 idt_B: 0.863 \n",
            "(epoch: 91, iters: 200, time: 0.575, data: 0.001) D_A: 0.039 G_A: 0.577 cycle_A: 1.441 idt_A: 0.535 D_B: 0.160 G_B: 1.053 cycle_B: 1.180 idt_B: 0.594 \n",
            "End of epoch 91 / 200 \t Time Taken: 107 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 92, iters: 100, time: 0.572, data: 0.169) D_A: 0.063 G_A: 0.869 cycle_A: 1.624 idt_A: 0.510 D_B: 0.100 G_B: 0.594 cycle_B: 1.333 idt_B: 0.526 \n",
            "(epoch: 92, iters: 200, time: 1.710, data: 0.001) D_A: 0.139 G_A: 0.469 cycle_A: 1.421 idt_A: 0.591 D_B: 0.127 G_B: 0.330 cycle_B: 1.321 idt_B: 0.418 \n",
            "End of epoch 92 / 200 \t Time Taken: 108 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 93, iters: 100, time: 0.576, data: 0.167) D_A: 0.120 G_A: 0.378 cycle_A: 1.379 idt_A: 0.417 D_B: 0.184 G_B: 0.275 cycle_B: 0.840 idt_B: 0.668 \n",
            "(epoch: 93, iters: 200, time: 0.574, data: 0.002) D_A: 0.073 G_A: 0.874 cycle_A: 0.921 idt_A: 0.822 D_B: 0.132 G_B: 0.481 cycle_B: 1.492 idt_B: 0.343 \n",
            "End of epoch 93 / 200 \t Time Taken: 107 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 94, iters: 100, time: 0.577, data: 0.182) D_A: 0.156 G_A: 0.326 cycle_A: 1.610 idt_A: 0.484 D_B: 0.075 G_B: 0.856 cycle_B: 1.089 idt_B: 0.589 \n",
            "(epoch: 94, iters: 200, time: 1.841, data: 0.001) D_A: 0.098 G_A: 0.667 cycle_A: 2.676 idt_A: 0.427 D_B: 0.069 G_B: 0.875 cycle_B: 1.023 idt_B: 0.941 \n",
            "End of epoch 94 / 200 \t Time Taken: 109 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 95, iters: 100, time: 0.570, data: 0.181) D_A: 0.228 G_A: 0.199 cycle_A: 1.403 idt_A: 0.452 D_B: 0.096 G_B: 0.681 cycle_B: 0.861 idt_B: 0.650 \n",
            "(epoch: 95, iters: 200, time: 0.578, data: 0.001) D_A: 0.136 G_A: 0.400 cycle_A: 0.843 idt_A: 0.371 D_B: 0.300 G_B: 0.137 cycle_B: 1.060 idt_B: 0.345 \n",
            "saving the model at the end of epoch 95, iters 19000\n",
            "End of epoch 95 / 200 \t Time Taken: 108 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 96, iters: 100, time: 0.573, data: 0.196) D_A: 0.124 G_A: 0.419 cycle_A: 0.909 idt_A: 0.597 D_B: 0.160 G_B: 0.779 cycle_B: 1.935 idt_B: 0.309 \n",
            "(epoch: 96, iters: 200, time: 1.772, data: 0.001) D_A: 0.094 G_A: 0.318 cycle_A: 1.185 idt_A: 0.413 D_B: 0.114 G_B: 0.418 cycle_B: 1.032 idt_B: 0.700 \n",
            "End of epoch 96 / 200 \t Time Taken: 108 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 97, iters: 100, time: 0.571, data: 0.177) D_A: 0.105 G_A: 0.519 cycle_A: 1.121 idt_A: 0.409 D_B: 0.168 G_B: 0.746 cycle_B: 1.133 idt_B: 0.473 \n",
            "(epoch: 97, iters: 200, time: 0.577, data: 0.001) D_A: 0.118 G_A: 0.533 cycle_A: 2.007 idt_A: 0.416 D_B: 0.295 G_B: 1.055 cycle_B: 1.126 idt_B: 1.345 \n",
            "End of epoch 97 / 200 \t Time Taken: 107 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 98, iters: 100, time: 0.576, data: 0.179) D_A: 0.114 G_A: 0.187 cycle_A: 1.015 idt_A: 0.661 D_B: 0.197 G_B: 0.775 cycle_B: 1.696 idt_B: 0.440 \n",
            "(epoch: 98, iters: 200, time: 1.771, data: 0.002) D_A: 0.087 G_A: 0.479 cycle_A: 1.332 idt_A: 0.357 D_B: 0.565 G_B: 1.092 cycle_B: 1.117 idt_B: 0.434 \n",
            "End of epoch 98 / 200 \t Time Taken: 108 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 99, iters: 100, time: 0.574, data: 0.168) D_A: 0.059 G_A: 0.798 cycle_A: 1.375 idt_A: 0.531 D_B: 0.175 G_B: 0.323 cycle_B: 0.967 idt_B: 0.690 \n",
            "(epoch: 99, iters: 200, time: 0.573, data: 0.001) D_A: 0.086 G_A: 0.234 cycle_A: 1.078 idt_A: 0.361 D_B: 0.332 G_B: 0.095 cycle_B: 0.994 idt_B: 0.483 \n",
            "End of epoch 99 / 200 \t Time Taken: 107 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 100, iters: 100, time: 0.572, data: 0.218) D_A: 0.110 G_A: 0.418 cycle_A: 1.065 idt_A: 0.389 D_B: 0.221 G_B: 0.729 cycle_B: 1.180 idt_B: 0.476 \n",
            "(epoch: 100, iters: 200, time: 2.023, data: 0.002) D_A: 0.065 G_A: 0.796 cycle_A: 1.093 idt_A: 0.360 D_B: 0.178 G_B: 0.311 cycle_B: 0.902 idt_B: 0.399 \n",
            "saving the latest model (epoch 100, total_iters 20000)\n",
            "saving the model at the end of epoch 100, iters 20000\n",
            "End of epoch 100 / 200 \t Time Taken: 112 sec\n",
            "learning rate = 0.0001980\n",
            "(epoch: 101, iters: 100, time: 0.575, data: 0.208) D_A: 0.106 G_A: 0.880 cycle_A: 1.260 idt_A: 0.521 D_B: 0.187 G_B: 0.537 cycle_B: 1.283 idt_B: 0.501 \n",
            "(epoch: 101, iters: 200, time: 0.575, data: 0.001) D_A: 0.063 G_A: 0.560 cycle_A: 1.513 idt_A: 0.359 D_B: 0.158 G_B: 0.336 cycle_B: 0.820 idt_B: 0.762 \n",
            "End of epoch 101 / 200 \t Time Taken: 107 sec\n",
            "learning rate = 0.0001960\n",
            "(epoch: 102, iters: 100, time: 0.576, data: 0.182) D_A: 0.156 G_A: 0.337 cycle_A: 1.125 idt_A: 0.416 D_B: 0.148 G_B: 0.299 cycle_B: 1.238 idt_B: 0.282 \n",
            "(epoch: 102, iters: 200, time: 1.795, data: 0.001) D_A: 0.097 G_A: 0.713 cycle_A: 1.366 idt_A: 0.575 D_B: 0.192 G_B: 0.867 cycle_B: 1.570 idt_B: 0.391 \n",
            "End of epoch 102 / 200 \t Time Taken: 108 sec\n",
            "learning rate = 0.0001941\n",
            "(epoch: 103, iters: 100, time: 0.571, data: 0.176) D_A: 0.038 G_A: 0.907 cycle_A: 0.885 idt_A: 0.362 D_B: 0.093 G_B: 0.565 cycle_B: 1.319 idt_B: 0.218 \n",
            "(epoch: 103, iters: 200, time: 0.577, data: 0.002) D_A: 0.075 G_A: 1.237 cycle_A: 1.732 idt_A: 1.177 D_B: 0.125 G_B: 0.611 cycle_B: 1.736 idt_B: 0.703 \n",
            "End of epoch 103 / 200 \t Time Taken: 107 sec\n",
            "learning rate = 0.0001921\n",
            "(epoch: 104, iters: 100, time: 0.573, data: 0.164) D_A: 0.089 G_A: 0.452 cycle_A: 1.123 idt_A: 0.555 D_B: 0.174 G_B: 0.922 cycle_B: 1.239 idt_B: 0.539 \n",
            "(epoch: 104, iters: 200, time: 1.817, data: 0.001) D_A: 0.103 G_A: 0.628 cycle_A: 1.371 idt_A: 1.061 D_B: 0.356 G_B: 0.924 cycle_B: 2.363 idt_B: 0.359 \n",
            "End of epoch 104 / 200 \t Time Taken: 109 sec\n",
            "learning rate = 0.0001901\n",
            "(epoch: 105, iters: 100, time: 0.575, data: 0.187) D_A: 0.087 G_A: 0.523 cycle_A: 0.948 idt_A: 0.519 D_B: 0.072 G_B: 0.824 cycle_B: 1.242 idt_B: 0.370 \n",
            "(epoch: 105, iters: 200, time: 0.574, data: 0.002) D_A: 0.070 G_A: 0.632 cycle_A: 1.621 idt_A: 0.491 D_B: 0.119 G_B: 0.432 cycle_B: 1.161 idt_B: 0.570 \n",
            "saving the model at the end of epoch 105, iters 21000\n",
            "End of epoch 105 / 200 \t Time Taken: 108 sec\n",
            "learning rate = 0.0001881\n",
            "(epoch: 106, iters: 100, time: 0.574, data: 0.195) D_A: 0.141 G_A: 0.314 cycle_A: 0.987 idt_A: 0.496 D_B: 0.110 G_B: 0.923 cycle_B: 1.032 idt_B: 0.616 \n",
            "(epoch: 106, iters: 200, time: 1.916, data: 0.001) D_A: 0.083 G_A: 0.408 cycle_A: 0.859 idt_A: 0.308 D_B: 0.140 G_B: 0.608 cycle_B: 0.792 idt_B: 0.345 \n",
            "End of epoch 106 / 200 \t Time Taken: 109 sec\n",
            "learning rate = 0.0001861\n",
            "(epoch: 107, iters: 100, time: 0.573, data: 0.176) D_A: 0.092 G_A: 0.560 cycle_A: 1.175 idt_A: 0.416 D_B: 0.121 G_B: 0.524 cycle_B: 0.924 idt_B: 0.553 \n",
            "(epoch: 107, iters: 200, time: 0.576, data: 0.001) D_A: 0.107 G_A: 0.623 cycle_A: 1.255 idt_A: 0.346 D_B: 0.184 G_B: 0.314 cycle_B: 0.980 idt_B: 0.521 \n",
            "End of epoch 107 / 200 \t Time Taken: 107 sec\n",
            "learning rate = 0.0001842\n",
            "(epoch: 108, iters: 100, time: 0.577, data: 0.167) D_A: 0.096 G_A: 0.694 cycle_A: 1.553 idt_A: 0.539 D_B: 0.064 G_B: 0.416 cycle_B: 1.309 idt_B: 0.746 \n",
            "(epoch: 108, iters: 200, time: 1.863, data: 0.001) D_A: 0.120 G_A: 0.613 cycle_A: 0.698 idt_A: 0.322 D_B: 0.148 G_B: 0.394 cycle_B: 1.126 idt_B: 0.226 \n",
            "End of epoch 108 / 200 \t Time Taken: 109 sec\n",
            "learning rate = 0.0001822\n",
            "(epoch: 109, iters: 100, time: 0.577, data: 0.190) D_A: 0.108 G_A: 0.801 cycle_A: 1.108 idt_A: 0.331 D_B: 0.161 G_B: 0.624 cycle_B: 0.928 idt_B: 0.322 \n",
            "(epoch: 109, iters: 200, time: 0.576, data: 0.001) D_A: 0.102 G_A: 0.480 cycle_A: 1.054 idt_A: 0.297 D_B: 0.067 G_B: 0.428 cycle_B: 0.874 idt_B: 0.374 \n",
            "End of epoch 109 / 200 \t Time Taken: 107 sec\n",
            "learning rate = 0.0001802\n",
            "(epoch: 110, iters: 100, time: 0.574, data: 0.169) D_A: 0.076 G_A: 0.673 cycle_A: 1.315 idt_A: 0.261 D_B: 0.283 G_B: 0.271 cycle_B: 0.609 idt_B: 0.360 \n",
            "(epoch: 110, iters: 200, time: 1.950, data: 0.001) D_A: 0.080 G_A: 0.293 cycle_A: 1.302 idt_A: 0.493 D_B: 0.106 G_B: 0.617 cycle_B: 1.260 idt_B: 0.432 \n",
            "saving the model at the end of epoch 110, iters 22000\n",
            "End of epoch 110 / 200 \t Time Taken: 110 sec\n",
            "learning rate = 0.0001782\n",
            "(epoch: 111, iters: 100, time: 0.572, data: 0.183) D_A: 0.088 G_A: 0.503 cycle_A: 2.603 idt_A: 0.558 D_B: 0.215 G_B: 0.318 cycle_B: 1.113 idt_B: 0.740 \n",
            "(epoch: 111, iters: 200, time: 0.573, data: 0.001) D_A: 0.109 G_A: 0.372 cycle_A: 1.178 idt_A: 0.707 D_B: 0.173 G_B: 0.402 cycle_B: 1.316 idt_B: 0.389 \n",
            "End of epoch 111 / 200 \t Time Taken: 107 sec\n",
            "learning rate = 0.0001762\n",
            "(epoch: 112, iters: 100, time: 0.575, data: 0.206) D_A: 0.102 G_A: 0.363 cycle_A: 0.998 idt_A: 0.343 D_B: 0.104 G_B: 0.503 cycle_B: 0.972 idt_B: 0.400 \n",
            "(epoch: 112, iters: 200, time: 2.016, data: 0.001) D_A: 0.101 G_A: 1.039 cycle_A: 1.465 idt_A: 0.380 D_B: 0.136 G_B: 0.549 cycle_B: 0.696 idt_B: 0.832 \n",
            "End of epoch 112 / 200 \t Time Taken: 109 sec\n",
            "learning rate = 0.0001743\n",
            "(epoch: 113, iters: 100, time: 0.576, data: 0.174) D_A: 0.125 G_A: 0.481 cycle_A: 1.356 idt_A: 0.670 D_B: 0.280 G_B: 0.438 cycle_B: 1.404 idt_B: 0.479 \n",
            "(epoch: 113, iters: 200, time: 0.577, data: 0.001) D_A: 0.242 G_A: 1.026 cycle_A: 0.880 idt_A: 0.347 D_B: 0.114 G_B: 0.197 cycle_B: 0.808 idt_B: 0.378 \n",
            "End of epoch 113 / 200 \t Time Taken: 108 sec\n",
            "learning rate = 0.0001723\n",
            "(epoch: 114, iters: 100, time: 0.573, data: 0.203) D_A: 0.128 G_A: 0.298 cycle_A: 1.147 idt_A: 0.507 D_B: 0.198 G_B: 0.412 cycle_B: 1.205 idt_B: 0.576 \n",
            "(epoch: 114, iters: 200, time: 1.919, data: 0.001) D_A: 0.055 G_A: 0.208 cycle_A: 0.986 idt_A: 0.581 D_B: 0.262 G_B: 0.922 cycle_B: 1.638 idt_B: 0.553 \n",
            "End of epoch 114 / 200 \t Time Taken: 109 sec\n",
            "learning rate = 0.0001703\n",
            "(epoch: 115, iters: 100, time: 0.575, data: 0.180) D_A: 0.036 G_A: 0.712 cycle_A: 1.031 idt_A: 0.378 D_B: 0.060 G_B: 0.597 cycle_B: 1.052 idt_B: 0.402 \n",
            "(epoch: 115, iters: 200, time: 0.577, data: 0.002) D_A: 0.086 G_A: 0.584 cycle_A: 1.072 idt_A: 0.602 D_B: 0.241 G_B: 0.252 cycle_B: 1.581 idt_B: 0.391 \n",
            "saving the model at the end of epoch 115, iters 23000\n",
            "End of epoch 115 / 200 \t Time Taken: 108 sec\n",
            "learning rate = 0.0001683\n",
            "(epoch: 116, iters: 100, time: 0.569, data: 0.226) D_A: 0.087 G_A: 0.541 cycle_A: 1.503 idt_A: 0.367 D_B: 0.211 G_B: 0.261 cycle_B: 1.102 idt_B: 0.576 \n",
            "(epoch: 116, iters: 200, time: 1.942, data: 0.002) D_A: 0.063 G_A: 0.368 cycle_A: 1.329 idt_A: 0.388 D_B: 0.210 G_B: 0.368 cycle_B: 0.879 idt_B: 0.388 \n",
            "End of epoch 116 / 200 \t Time Taken: 109 sec\n",
            "learning rate = 0.0001663\n",
            "(epoch: 117, iters: 100, time: 0.575, data: 0.178) D_A: 0.084 G_A: 0.887 cycle_A: 0.806 idt_A: 0.304 D_B: 0.065 G_B: 0.867 cycle_B: 0.783 idt_B: 0.276 \n",
            "(epoch: 117, iters: 200, time: 0.574, data: 0.002) D_A: 0.052 G_A: 0.807 cycle_A: 1.341 idt_A: 0.378 D_B: 0.289 G_B: 0.178 cycle_B: 1.025 idt_B: 0.499 \n",
            "End of epoch 117 / 200 \t Time Taken: 107 sec\n",
            "learning rate = 0.0001644\n",
            "(epoch: 118, iters: 100, time: 0.574, data: 0.168) D_A: 0.216 G_A: 0.236 cycle_A: 1.301 idt_A: 0.410 D_B: 0.091 G_B: 0.838 cycle_B: 1.255 idt_B: 0.567 \n",
            "(epoch: 118, iters: 200, time: 1.982, data: 0.002) D_A: 0.041 G_A: 0.269 cycle_A: 1.308 idt_A: 0.433 D_B: 0.206 G_B: 0.802 cycle_B: 0.952 idt_B: 0.460 \n",
            "End of epoch 118 / 200 \t Time Taken: 108 sec\n",
            "learning rate = 0.0001624\n",
            "(epoch: 119, iters: 100, time: 0.575, data: 0.180) D_A: 0.049 G_A: 0.279 cycle_A: 1.242 idt_A: 0.449 D_B: 0.055 G_B: 0.751 cycle_B: 1.179 idt_B: 0.473 \n",
            "(epoch: 119, iters: 200, time: 0.575, data: 0.001) D_A: 0.118 G_A: 0.586 cycle_A: 1.292 idt_A: 0.443 D_B: 0.278 G_B: 0.359 cycle_B: 0.861 idt_B: 0.728 \n",
            "End of epoch 119 / 200 \t Time Taken: 107 sec\n",
            "learning rate = 0.0001604\n",
            "(epoch: 120, iters: 100, time: 0.572, data: 0.180) D_A: 0.055 G_A: 1.171 cycle_A: 0.991 idt_A: 0.507 D_B: 0.084 G_B: 1.013 cycle_B: 1.333 idt_B: 0.527 \n",
            "(epoch: 120, iters: 200, time: 1.992, data: 0.001) D_A: 0.059 G_A: 0.613 cycle_A: 1.021 idt_A: 0.544 D_B: 0.188 G_B: 0.704 cycle_B: 1.401 idt_B: 0.432 \n",
            "saving the model at the end of epoch 120, iters 24000\n",
            "End of epoch 120 / 200 \t Time Taken: 109 sec\n",
            "learning rate = 0.0001584\n",
            "(epoch: 121, iters: 100, time: 0.576, data: 0.199) D_A: 0.108 G_A: 0.517 cycle_A: 1.653 idt_A: 0.392 D_B: 0.078 G_B: 0.917 cycle_B: 0.950 idt_B: 0.470 \n",
            "(epoch: 121, iters: 200, time: 0.573, data: 0.001) D_A: 0.153 G_A: 0.587 cycle_A: 1.515 idt_A: 0.401 D_B: 0.255 G_B: 0.188 cycle_B: 1.077 idt_B: 0.667 \n",
            "End of epoch 121 / 200 \t Time Taken: 107 sec\n",
            "learning rate = 0.0001564\n",
            "(epoch: 122, iters: 100, time: 0.572, data: 0.172) D_A: 0.102 G_A: 0.483 cycle_A: 1.651 idt_A: 0.406 D_B: 0.116 G_B: 0.554 cycle_B: 0.919 idt_B: 0.565 \n",
            "(epoch: 122, iters: 200, time: 1.992, data: 0.002) D_A: 0.087 G_A: 0.531 cycle_A: 0.861 idt_A: 0.512 D_B: 0.076 G_B: 0.505 cycle_B: 0.976 idt_B: 0.386 \n",
            "End of epoch 122 / 200 \t Time Taken: 108 sec\n",
            "learning rate = 0.0001545\n",
            "(epoch: 123, iters: 100, time: 0.575, data: 0.178) D_A: 0.090 G_A: 0.202 cycle_A: 1.141 idt_A: 0.286 D_B: 0.082 G_B: 0.705 cycle_B: 0.756 idt_B: 0.372 \n",
            "(epoch: 123, iters: 200, time: 0.573, data: 0.001) D_A: 0.207 G_A: 1.179 cycle_A: 0.776 idt_A: 0.330 D_B: 0.092 G_B: 0.692 cycle_B: 1.149 idt_B: 0.340 \n",
            "End of epoch 123 / 200 \t Time Taken: 107 sec\n",
            "learning rate = 0.0001525\n",
            "(epoch: 124, iters: 100, time: 0.576, data: 0.163) D_A: 0.091 G_A: 0.837 cycle_A: 0.999 idt_A: 0.338 D_B: 0.142 G_B: 0.330 cycle_B: 0.772 idt_B: 0.354 \n",
            "(epoch: 124, iters: 200, time: 1.966, data: 0.001) D_A: 0.144 G_A: 0.556 cycle_A: 1.469 idt_A: 0.653 D_B: 0.161 G_B: 0.489 cycle_B: 1.235 idt_B: 0.387 \n",
            "End of epoch 124 / 200 \t Time Taken: 109 sec\n",
            "learning rate = 0.0001505\n",
            "(epoch: 125, iters: 100, time: 0.573, data: 0.186) D_A: 0.162 G_A: 0.757 cycle_A: 0.983 idt_A: 0.438 D_B: 0.160 G_B: 0.506 cycle_B: 1.108 idt_B: 0.499 \n",
            "(epoch: 125, iters: 200, time: 0.574, data: 0.002) D_A: 0.093 G_A: 0.197 cycle_A: 1.170 idt_A: 0.476 D_B: 0.072 G_B: 0.616 cycle_B: 1.084 idt_B: 0.418 \n",
            "saving the latest model (epoch 125, total_iters 25000)\n",
            "saving the model at the end of epoch 125, iters 25000\n",
            "End of epoch 125 / 200 \t Time Taken: 111 sec\n",
            "learning rate = 0.0001485\n",
            "(epoch: 126, iters: 100, time: 0.573, data: 0.201) D_A: 0.043 G_A: 0.470 cycle_A: 0.986 idt_A: 0.382 D_B: 0.144 G_B: 0.415 cycle_B: 1.039 idt_B: 0.471 \n",
            "(epoch: 126, iters: 200, time: 1.991, data: 0.001) D_A: 0.041 G_A: 0.722 cycle_A: 2.447 idt_A: 0.575 D_B: 0.085 G_B: 0.245 cycle_B: 1.253 idt_B: 1.514 \n",
            "End of epoch 126 / 200 \t Time Taken: 109 sec\n",
            "learning rate = 0.0001465\n",
            "(epoch: 127, iters: 100, time: 0.574, data: 0.166) D_A: 0.093 G_A: 0.835 cycle_A: 1.968 idt_A: 0.324 D_B: 0.085 G_B: 0.506 cycle_B: 1.066 idt_B: 0.418 \n",
            "(epoch: 127, iters: 200, time: 0.570, data: 0.001) D_A: 0.093 G_A: 0.514 cycle_A: 0.905 idt_A: 0.253 D_B: 0.095 G_B: 0.556 cycle_B: 0.842 idt_B: 0.232 \n",
            "End of epoch 127 / 200 \t Time Taken: 107 sec\n",
            "learning rate = 0.0001446\n",
            "(epoch: 128, iters: 100, time: 0.571, data: 0.189) D_A: 0.053 G_A: 0.354 cycle_A: 1.572 idt_A: 0.443 D_B: 0.235 G_B: 0.190 cycle_B: 1.084 idt_B: 0.543 \n",
            "(epoch: 128, iters: 200, time: 2.025, data: 0.001) D_A: 0.111 G_A: 0.562 cycle_A: 1.083 idt_A: 0.295 D_B: 0.220 G_B: 0.402 cycle_B: 0.803 idt_B: 0.368 \n",
            "End of epoch 128 / 200 \t Time Taken: 108 sec\n",
            "learning rate = 0.0001426\n",
            "(epoch: 129, iters: 100, time: 0.570, data: 0.165) D_A: 0.198 G_A: 0.260 cycle_A: 1.011 idt_A: 0.355 D_B: 0.083 G_B: 0.874 cycle_B: 1.149 idt_B: 0.363 \n",
            "(epoch: 129, iters: 200, time: 0.573, data: 0.001) D_A: 0.096 G_A: 0.562 cycle_A: 0.940 idt_A: 0.430 D_B: 0.064 G_B: 0.611 cycle_B: 1.315 idt_B: 0.335 \n",
            "End of epoch 129 / 200 \t Time Taken: 107 sec\n",
            "learning rate = 0.0001406\n",
            "(epoch: 130, iters: 100, time: 0.574, data: 0.182) D_A: 0.085 G_A: 0.658 cycle_A: 0.980 idt_A: 0.418 D_B: 0.380 G_B: 0.471 cycle_B: 1.178 idt_B: 0.251 \n",
            "(epoch: 130, iters: 200, time: 1.999, data: 0.001) D_A: 0.187 G_A: 0.293 cycle_A: 0.759 idt_A: 0.298 D_B: 0.156 G_B: 0.531 cycle_B: 0.930 idt_B: 0.447 \n",
            "saving the model at the end of epoch 130, iters 26000\n",
            "End of epoch 130 / 200 \t Time Taken: 109 sec\n",
            "learning rate = 0.0001386\n",
            "(epoch: 131, iters: 100, time: 0.576, data: 0.192) D_A: 0.125 G_A: 0.487 cycle_A: 0.938 idt_A: 0.312 D_B: 0.122 G_B: 0.555 cycle_B: 0.873 idt_B: 0.356 \n",
            "(epoch: 131, iters: 200, time: 0.573, data: 0.002) D_A: 0.101 G_A: 0.633 cycle_A: 0.891 idt_A: 0.289 D_B: 0.112 G_B: 0.321 cycle_B: 0.894 idt_B: 0.276 \n",
            "End of epoch 131 / 200 \t Time Taken: 107 sec\n",
            "learning rate = 0.0001366\n",
            "(epoch: 132, iters: 100, time: 0.573, data: 0.181) D_A: 0.063 G_A: 0.740 cycle_A: 0.770 idt_A: 0.288 D_B: 0.037 G_B: 0.769 cycle_B: 1.027 idt_B: 0.331 \n",
            "(epoch: 132, iters: 200, time: 1.996, data: 0.001) D_A: 0.150 G_A: 0.333 cycle_A: 0.973 idt_A: 0.360 D_B: 0.237 G_B: 0.398 cycle_B: 0.991 idt_B: 0.383 \n",
            "End of epoch 132 / 200 \t Time Taken: 108 sec\n",
            "learning rate = 0.0001347\n",
            "(epoch: 133, iters: 100, time: 0.577, data: 0.206) D_A: 0.067 G_A: 0.839 cycle_A: 1.111 idt_A: 0.382 D_B: 0.152 G_B: 0.475 cycle_B: 1.137 idt_B: 0.395 \n",
            "(epoch: 133, iters: 200, time: 0.572, data: 0.001) D_A: 0.026 G_A: 0.194 cycle_A: 1.157 idt_A: 0.315 D_B: 0.163 G_B: 0.454 cycle_B: 0.889 idt_B: 0.260 \n",
            "End of epoch 133 / 200 \t Time Taken: 107 sec\n",
            "learning rate = 0.0001327\n",
            "(epoch: 134, iters: 100, time: 0.577, data: 0.169) D_A: 0.032 G_A: 0.468 cycle_A: 0.887 idt_A: 0.354 D_B: 0.128 G_B: 0.904 cycle_B: 0.905 idt_B: 0.350 \n",
            "(epoch: 134, iters: 200, time: 1.993, data: 0.001) D_A: 0.133 G_A: 0.566 cycle_A: 1.094 idt_A: 0.348 D_B: 0.057 G_B: 0.586 cycle_B: 0.883 idt_B: 0.443 \n",
            "End of epoch 134 / 200 \t Time Taken: 109 sec\n",
            "learning rate = 0.0001307\n",
            "(epoch: 135, iters: 100, time: 0.576, data: 0.165) D_A: 0.107 G_A: 1.075 cycle_A: 1.066 idt_A: 0.454 D_B: 0.224 G_B: 0.222 cycle_B: 1.078 idt_B: 0.327 \n",
            "(epoch: 135, iters: 200, time: 0.575, data: 0.001) D_A: 0.113 G_A: 1.497 cycle_A: 1.171 idt_A: 0.411 D_B: 0.058 G_B: 0.972 cycle_B: 0.939 idt_B: 0.424 \n",
            "saving the model at the end of epoch 135, iters 27000\n",
            "End of epoch 135 / 200 \t Time Taken: 108 sec\n",
            "learning rate = 0.0001287\n",
            "(epoch: 136, iters: 100, time: 0.570, data: 0.185) D_A: 0.051 G_A: 0.298 cycle_A: 1.810 idt_A: 0.357 D_B: 0.112 G_B: 0.190 cycle_B: 1.184 idt_B: 0.324 \n",
            "(epoch: 136, iters: 200, time: 2.028, data: 0.001) D_A: 0.142 G_A: 0.813 cycle_A: 1.339 idt_A: 0.358 D_B: 0.299 G_B: 0.215 cycle_B: 0.862 idt_B: 0.640 \n",
            "End of epoch 136 / 200 \t Time Taken: 109 sec\n",
            "learning rate = 0.0001267\n",
            "(epoch: 137, iters: 100, time: 0.576, data: 0.183) D_A: 0.049 G_A: 0.718 cycle_A: 1.213 idt_A: 0.502 D_B: 0.107 G_B: 0.765 cycle_B: 1.082 idt_B: 0.317 \n",
            "(epoch: 137, iters: 200, time: 0.574, data: 0.001) D_A: 0.143 G_A: 1.051 cycle_A: 0.969 idt_A: 0.331 D_B: 0.195 G_B: 0.195 cycle_B: 0.893 idt_B: 0.263 \n",
            "End of epoch 137 / 200 \t Time Taken: 107 sec\n",
            "learning rate = 0.0001248\n",
            "(epoch: 138, iters: 100, time: 0.577, data: 0.176) D_A: 0.045 G_A: 0.375 cycle_A: 0.971 idt_A: 0.426 D_B: 0.163 G_B: 0.369 cycle_B: 1.141 idt_B: 0.354 \n",
            "(epoch: 138, iters: 200, time: 1.994, data: 0.001) D_A: 0.121 G_A: 0.570 cycle_A: 0.867 idt_A: 0.301 D_B: 0.082 G_B: 0.515 cycle_B: 1.138 idt_B: 0.257 \n",
            "End of epoch 138 / 200 \t Time Taken: 109 sec\n",
            "learning rate = 0.0001228\n",
            "(epoch: 139, iters: 100, time: 0.578, data: 0.176) D_A: 0.112 G_A: 0.508 cycle_A: 0.995 idt_A: 0.288 D_B: 0.151 G_B: 0.506 cycle_B: 0.817 idt_B: 0.369 \n",
            "(epoch: 139, iters: 200, time: 0.569, data: 0.001) D_A: 0.067 G_A: 0.625 cycle_A: 0.741 idt_A: 0.280 D_B: 0.152 G_B: 0.373 cycle_B: 0.971 idt_B: 0.183 \n",
            "End of epoch 139 / 200 \t Time Taken: 107 sec\n",
            "learning rate = 0.0001208\n",
            "(epoch: 140, iters: 100, time: 0.571, data: 0.171) D_A: 0.124 G_A: 0.549 cycle_A: 0.765 idt_A: 0.370 D_B: 0.026 G_B: 1.035 cycle_B: 0.828 idt_B: 0.458 \n",
            "(epoch: 140, iters: 200, time: 2.019, data: 0.002) D_A: 0.061 G_A: 0.684 cycle_A: 0.816 idt_A: 0.464 D_B: 0.208 G_B: 0.251 cycle_B: 1.013 idt_B: 0.256 \n",
            "saving the model at the end of epoch 140, iters 28000\n",
            "End of epoch 140 / 200 \t Time Taken: 109 sec\n",
            "learning rate = 0.0001188\n",
            "(epoch: 141, iters: 100, time: 0.576, data: 0.205) D_A: 0.060 G_A: 0.454 cycle_A: 1.349 idt_A: 0.289 D_B: 0.137 G_B: 0.479 cycle_B: 1.034 idt_B: 0.634 \n",
            "(epoch: 141, iters: 200, time: 0.575, data: 0.002) D_A: 0.094 G_A: 0.452 cycle_A: 0.994 idt_A: 0.257 D_B: 0.133 G_B: 0.633 cycle_B: 0.670 idt_B: 0.246 \n",
            "End of epoch 141 / 200 \t Time Taken: 107 sec\n",
            "learning rate = 0.0001168\n",
            "(epoch: 142, iters: 100, time: 0.571, data: 0.181) D_A: 0.169 G_A: 0.494 cycle_A: 1.115 idt_A: 0.383 D_B: 0.179 G_B: 0.354 cycle_B: 1.276 idt_B: 0.880 \n",
            "(epoch: 142, iters: 200, time: 2.104, data: 0.001) D_A: 0.064 G_A: 0.470 cycle_A: 1.121 idt_A: 0.347 D_B: 0.055 G_B: 0.708 cycle_B: 0.934 idt_B: 0.308 \n",
            "End of epoch 142 / 200 \t Time Taken: 108 sec\n",
            "learning rate = 0.0001149\n",
            "(epoch: 143, iters: 100, time: 0.578, data: 0.162) D_A: 0.031 G_A: 0.327 cycle_A: 1.199 idt_A: 0.616 D_B: 0.088 G_B: 0.532 cycle_B: 1.198 idt_B: 0.475 \n",
            "(epoch: 143, iters: 200, time: 0.575, data: 0.001) D_A: 0.074 G_A: 0.874 cycle_A: 1.136 idt_A: 0.400 D_B: 0.068 G_B: 0.870 cycle_B: 1.041 idt_B: 0.407 \n",
            "End of epoch 143 / 200 \t Time Taken: 107 sec\n",
            "learning rate = 0.0001129\n",
            "(epoch: 144, iters: 100, time: 0.566, data: 0.166) D_A: 0.133 G_A: 0.342 cycle_A: 1.566 idt_A: 0.394 D_B: 0.090 G_B: 0.848 cycle_B: 1.076 idt_B: 0.357 \n",
            "(epoch: 144, iters: 200, time: 2.043, data: 0.001) D_A: 0.090 G_A: 0.442 cycle_A: 0.787 idt_A: 0.320 D_B: 0.333 G_B: 0.086 cycle_B: 0.780 idt_B: 0.251 \n",
            "End of epoch 144 / 200 \t Time Taken: 108 sec\n",
            "learning rate = 0.0001109\n",
            "(epoch: 145, iters: 100, time: 0.576, data: 0.164) D_A: 0.109 G_A: 0.425 cycle_A: 0.691 idt_A: 0.359 D_B: 0.126 G_B: 0.212 cycle_B: 1.074 idt_B: 0.201 \n",
            "(epoch: 145, iters: 200, time: 0.571, data: 0.001) D_A: 0.106 G_A: 1.367 cycle_A: 0.816 idt_A: 0.301 D_B: 0.134 G_B: 0.469 cycle_B: 1.105 idt_B: 0.245 \n",
            "saving the model at the end of epoch 145, iters 29000\n",
            "End of epoch 145 / 200 \t Time Taken: 108 sec\n",
            "learning rate = 0.0001089\n",
            "(epoch: 146, iters: 100, time: 0.571, data: 0.181) D_A: 0.094 G_A: 0.956 cycle_A: 0.865 idt_A: 0.278 D_B: 0.091 G_B: 0.911 cycle_B: 0.738 idt_B: 0.241 \n",
            "(epoch: 146, iters: 200, time: 2.135, data: 0.002) D_A: 0.054 G_A: 0.886 cycle_A: 0.945 idt_A: 0.330 D_B: 0.145 G_B: 0.203 cycle_B: 1.042 idt_B: 0.365 \n",
            "End of epoch 146 / 200 \t Time Taken: 109 sec\n",
            "learning rate = 0.0001069\n",
            "(epoch: 147, iters: 100, time: 0.576, data: 0.179) D_A: 0.062 G_A: 0.519 cycle_A: 0.754 idt_A: 0.441 D_B: 0.087 G_B: 0.474 cycle_B: 1.347 idt_B: 0.226 \n",
            "(epoch: 147, iters: 200, time: 0.575, data: 0.001) D_A: 0.159 G_A: 0.721 cycle_A: 0.901 idt_A: 0.235 D_B: 0.241 G_B: 1.150 cycle_B: 0.723 idt_B: 0.330 \n",
            "End of epoch 147 / 200 \t Time Taken: 107 sec\n",
            "learning rate = 0.0001050\n",
            "(epoch: 148, iters: 100, time: 0.572, data: 0.183) D_A: 0.121 G_A: 0.279 cycle_A: 1.305 idt_A: 0.425 D_B: 0.057 G_B: 0.734 cycle_B: 1.296 idt_B: 0.558 \n",
            "(epoch: 148, iters: 200, time: 2.192, data: 0.001) D_A: 0.144 G_A: 0.300 cycle_A: 0.951 idt_A: 0.370 D_B: 0.144 G_B: 0.395 cycle_B: 1.209 idt_B: 0.278 \n",
            "End of epoch 148 / 200 \t Time Taken: 109 sec\n",
            "learning rate = 0.0001030\n",
            "(epoch: 149, iters: 100, time: 0.574, data: 0.168) D_A: 0.082 G_A: 0.589 cycle_A: 1.008 idt_A: 0.316 D_B: 0.145 G_B: 0.498 cycle_B: 0.953 idt_B: 0.396 \n",
            "(epoch: 149, iters: 200, time: 0.575, data: 0.002) D_A: 0.056 G_A: 0.586 cycle_A: 0.938 idt_A: 0.270 D_B: 0.118 G_B: 0.584 cycle_B: 0.712 idt_B: 0.356 \n",
            "End of epoch 149 / 200 \t Time Taken: 107 sec\n",
            "learning rate = 0.0001010\n",
            "(epoch: 150, iters: 100, time: 0.567, data: 0.164) D_A: 0.074 G_A: 0.614 cycle_A: 0.968 idt_A: 0.295 D_B: 0.107 G_B: 0.405 cycle_B: 0.893 idt_B: 0.288 \n",
            "(epoch: 150, iters: 200, time: 2.150, data: 0.002) D_A: 0.217 G_A: 0.251 cycle_A: 0.828 idt_A: 0.603 D_B: 0.156 G_B: 0.966 cycle_B: 1.301 idt_B: 0.373 \n",
            "saving the latest model (epoch 150, total_iters 30000)\n",
            "saving the model at the end of epoch 150, iters 30000\n",
            "End of epoch 150 / 200 \t Time Taken: 112 sec\n",
            "learning rate = 0.0000990\n",
            "(epoch: 151, iters: 100, time: 0.575, data: 0.221) D_A: 0.064 G_A: 0.561 cycle_A: 0.831 idt_A: 0.357 D_B: 0.159 G_B: 1.408 cycle_B: 0.874 idt_B: 0.400 \n",
            "(epoch: 151, iters: 200, time: 0.577, data: 0.001) D_A: 0.070 G_A: 0.708 cycle_A: 0.972 idt_A: 0.546 D_B: 0.069 G_B: 0.387 cycle_B: 1.297 idt_B: 0.263 \n",
            "End of epoch 151 / 200 \t Time Taken: 107 sec\n",
            "learning rate = 0.0000970\n",
            "(epoch: 152, iters: 100, time: 0.579, data: 0.175) D_A: 0.124 G_A: 0.420 cycle_A: 1.133 idt_A: 0.332 D_B: 0.097 G_B: 0.497 cycle_B: 1.047 idt_B: 0.492 \n",
            "(epoch: 152, iters: 200, time: 2.148, data: 0.001) D_A: 0.241 G_A: 0.146 cycle_A: 0.753 idt_A: 0.244 D_B: 0.046 G_B: 0.174 cycle_B: 0.809 idt_B: 0.269 \n",
            "End of epoch 152 / 200 \t Time Taken: 109 sec\n",
            "learning rate = 0.0000950\n",
            "(epoch: 153, iters: 100, time: 0.574, data: 0.175) D_A: 0.227 G_A: 0.194 cycle_A: 1.053 idt_A: 0.265 D_B: 0.268 G_B: 0.452 cycle_B: 0.827 idt_B: 0.646 \n",
            "(epoch: 153, iters: 200, time: 0.576, data: 0.001) D_A: 0.030 G_A: 0.591 cycle_A: 0.846 idt_A: 0.331 D_B: 0.166 G_B: 0.367 cycle_B: 0.794 idt_B: 0.198 \n",
            "End of epoch 153 / 200 \t Time Taken: 107 sec\n",
            "learning rate = 0.0000931\n",
            "(epoch: 154, iters: 100, time: 0.577, data: 0.173) D_A: 0.238 G_A: 0.585 cycle_A: 1.011 idt_A: 0.400 D_B: 0.235 G_B: 0.316 cycle_B: 0.818 idt_B: 0.323 \n",
            "(epoch: 154, iters: 200, time: 2.248, data: 0.002) D_A: 0.139 G_A: 0.329 cycle_A: 0.999 idt_A: 0.273 D_B: 0.161 G_B: 0.719 cycle_B: 0.734 idt_B: 0.298 \n",
            "End of epoch 154 / 200 \t Time Taken: 109 sec\n",
            "learning rate = 0.0000911\n",
            "(epoch: 155, iters: 100, time: 0.576, data: 0.202) D_A: 0.142 G_A: 0.352 cycle_A: 0.942 idt_A: 0.405 D_B: 0.176 G_B: 0.269 cycle_B: 1.022 idt_B: 0.281 \n",
            "(epoch: 155, iters: 200, time: 0.575, data: 0.002) D_A: 0.220 G_A: 0.457 cycle_A: 0.831 idt_A: 0.309 D_B: 0.245 G_B: 0.857 cycle_B: 0.886 idt_B: 0.216 \n",
            "saving the model at the end of epoch 155, iters 31000\n",
            "End of epoch 155 / 200 \t Time Taken: 108 sec\n",
            "learning rate = 0.0000891\n",
            "(epoch: 156, iters: 100, time: 0.575, data: 0.187) D_A: 0.043 G_A: 0.673 cycle_A: 0.893 idt_A: 0.370 D_B: 0.116 G_B: 0.481 cycle_B: 1.129 idt_B: 0.247 \n",
            "(epoch: 156, iters: 200, time: 2.171, data: 0.001) D_A: 0.141 G_A: 0.793 cycle_A: 0.865 idt_A: 0.329 D_B: 0.253 G_B: 0.512 cycle_B: 0.990 idt_B: 0.292 \n",
            "End of epoch 156 / 200 \t Time Taken: 109 sec\n",
            "learning rate = 0.0000871\n",
            "(epoch: 157, iters: 100, time: 0.575, data: 0.163) D_A: 0.049 G_A: 0.884 cycle_A: 1.021 idt_A: 0.501 D_B: 0.182 G_B: 0.474 cycle_B: 0.871 idt_B: 0.232 \n",
            "(epoch: 157, iters: 200, time: 0.571, data: 0.001) D_A: 0.080 G_A: 0.604 cycle_A: 0.863 idt_A: 0.283 D_B: 0.108 G_B: 0.382 cycle_B: 0.954 idt_B: 0.282 \n",
            "End of epoch 157 / 200 \t Time Taken: 107 sec\n",
            "learning rate = 0.0000851\n",
            "(epoch: 158, iters: 100, time: 0.576, data: 0.181) D_A: 0.089 G_A: 0.213 cycle_A: 0.893 idt_A: 0.216 D_B: 0.158 G_B: 0.678 cycle_B: 0.734 idt_B: 0.206 \n",
            "(epoch: 158, iters: 200, time: 2.203, data: 0.001) D_A: 0.098 G_A: 0.817 cycle_A: 1.084 idt_A: 0.446 D_B: 0.085 G_B: 0.779 cycle_B: 1.211 idt_B: 0.449 \n",
            "End of epoch 158 / 200 \t Time Taken: 109 sec\n",
            "learning rate = 0.0000832\n",
            "(epoch: 159, iters: 100, time: 0.574, data: 0.177) D_A: 0.139 G_A: 0.937 cycle_A: 1.197 idt_A: 0.318 D_B: 0.227 G_B: 0.174 cycle_B: 0.828 idt_B: 0.218 \n",
            "(epoch: 159, iters: 200, time: 0.573, data: 0.001) D_A: 0.108 G_A: 0.273 cycle_A: 1.178 idt_A: 0.348 D_B: 0.106 G_B: 0.558 cycle_B: 0.942 idt_B: 0.349 \n",
            "End of epoch 159 / 200 \t Time Taken: 107 sec\n",
            "learning rate = 0.0000812\n",
            "(epoch: 160, iters: 100, time: 0.575, data: 0.195) D_A: 0.061 G_A: 0.942 cycle_A: 1.158 idt_A: 0.363 D_B: 0.138 G_B: 0.530 cycle_B: 0.832 idt_B: 0.369 \n",
            "(epoch: 160, iters: 200, time: 2.289, data: 0.001) D_A: 0.060 G_A: 0.411 cycle_A: 0.890 idt_A: 0.354 D_B: 0.295 G_B: 0.589 cycle_B: 1.025 idt_B: 0.314 \n",
            "saving the model at the end of epoch 160, iters 32000\n",
            "End of epoch 160 / 200 \t Time Taken: 110 sec\n",
            "learning rate = 0.0000792\n",
            "(epoch: 161, iters: 100, time: 0.575, data: 0.189) D_A: 0.085 G_A: 0.738 cycle_A: 0.913 idt_A: 0.295 D_B: 0.120 G_B: 0.828 cycle_B: 0.791 idt_B: 0.245 \n",
            "(epoch: 161, iters: 200, time: 0.568, data: 0.001) D_A: 0.118 G_A: 0.419 cycle_A: 1.140 idt_A: 0.282 D_B: 0.069 G_B: 0.525 cycle_B: 0.931 idt_B: 0.365 \n",
            "End of epoch 161 / 200 \t Time Taken: 107 sec\n",
            "learning rate = 0.0000772\n",
            "(epoch: 162, iters: 100, time: 0.573, data: 0.175) D_A: 0.040 G_A: 0.912 cycle_A: 0.897 idt_A: 0.241 D_B: 0.137 G_B: 0.539 cycle_B: 0.947 idt_B: 0.229 \n",
            "(epoch: 162, iters: 200, time: 2.180, data: 0.001) D_A: 0.061 G_A: 0.556 cycle_A: 1.236 idt_A: 0.300 D_B: 0.266 G_B: 0.106 cycle_B: 0.977 idt_B: 0.400 \n",
            "End of epoch 162 / 200 \t Time Taken: 109 sec\n",
            "learning rate = 0.0000752\n",
            "(epoch: 163, iters: 100, time: 0.577, data: 0.185) D_A: 0.063 G_A: 0.887 cycle_A: 1.133 idt_A: 0.322 D_B: 0.079 G_B: 0.483 cycle_B: 0.794 idt_B: 0.299 \n",
            "(epoch: 163, iters: 200, time: 0.575, data: 0.001) D_A: 0.120 G_A: 0.902 cycle_A: 0.864 idt_A: 0.319 D_B: 0.072 G_B: 0.369 cycle_B: 1.028 idt_B: 0.266 \n",
            "End of epoch 163 / 200 \t Time Taken: 107 sec\n",
            "learning rate = 0.0000733\n",
            "(epoch: 164, iters: 100, time: 0.574, data: 0.178) D_A: 0.040 G_A: 0.552 cycle_A: 0.877 idt_A: 0.331 D_B: 0.195 G_B: 0.250 cycle_B: 0.902 idt_B: 0.200 \n",
            "(epoch: 164, iters: 200, time: 2.231, data: 0.001) D_A: 0.082 G_A: 0.771 cycle_A: 0.648 idt_A: 0.378 D_B: 0.099 G_B: 0.275 cycle_B: 0.931 idt_B: 0.252 \n",
            "End of epoch 164 / 200 \t Time Taken: 109 sec\n",
            "learning rate = 0.0000713\n",
            "(epoch: 165, iters: 100, time: 0.577, data: 0.171) D_A: 0.034 G_A: 0.605 cycle_A: 1.030 idt_A: 0.261 D_B: 0.350 G_B: 0.948 cycle_B: 0.847 idt_B: 0.316 \n",
            "(epoch: 165, iters: 200, time: 0.574, data: 0.002) D_A: 0.111 G_A: 0.560 cycle_A: 1.195 idt_A: 0.526 D_B: 0.163 G_B: 0.394 cycle_B: 1.037 idt_B: 0.351 \n",
            "saving the model at the end of epoch 165, iters 33000\n",
            "End of epoch 165 / 200 \t Time Taken: 108 sec\n",
            "learning rate = 0.0000693\n",
            "(epoch: 166, iters: 100, time: 0.574, data: 0.192) D_A: 0.031 G_A: 0.698 cycle_A: 0.736 idt_A: 0.296 D_B: 0.193 G_B: 0.411 cycle_B: 0.815 idt_B: 0.304 \n",
            "(epoch: 166, iters: 200, time: 2.284, data: 0.001) D_A: 0.215 G_A: 0.425 cycle_A: 1.234 idt_A: 0.329 D_B: 0.077 G_B: 0.381 cycle_B: 0.968 idt_B: 0.363 \n",
            "End of epoch 166 / 200 \t Time Taken: 109 sec\n",
            "learning rate = 0.0000673\n",
            "(epoch: 167, iters: 100, time: 0.572, data: 0.174) D_A: 0.044 G_A: 0.751 cycle_A: 0.768 idt_A: 0.333 D_B: 0.114 G_B: 0.529 cycle_B: 0.827 idt_B: 0.233 \n",
            "(epoch: 167, iters: 200, time: 0.575, data: 0.001) D_A: 0.062 G_A: 0.848 cycle_A: 0.896 idt_A: 0.234 D_B: 0.159 G_B: 0.426 cycle_B: 0.634 idt_B: 0.271 \n",
            "End of epoch 167 / 200 \t Time Taken: 107 sec\n",
            "learning rate = 0.0000653\n",
            "(epoch: 168, iters: 100, time: 0.575, data: 0.176) D_A: 0.042 G_A: 0.686 cycle_A: 1.381 idt_A: 0.382 D_B: 0.095 G_B: 0.689 cycle_B: 1.222 idt_B: 1.387 \n",
            "(epoch: 168, iters: 200, time: 2.273, data: 0.001) D_A: 0.079 G_A: 0.657 cycle_A: 0.700 idt_A: 0.287 D_B: 0.174 G_B: 0.444 cycle_B: 0.725 idt_B: 0.203 \n",
            "End of epoch 168 / 200 \t Time Taken: 109 sec\n",
            "learning rate = 0.0000634\n",
            "(epoch: 169, iters: 100, time: 0.578, data: 0.175) D_A: 0.167 G_A: 0.427 cycle_A: 0.996 idt_A: 0.340 D_B: 0.059 G_B: 0.639 cycle_B: 0.885 idt_B: 0.177 \n",
            "(epoch: 169, iters: 200, time: 0.574, data: 0.002) D_A: 0.099 G_A: 0.623 cycle_A: 0.600 idt_A: 0.305 D_B: 0.096 G_B: 0.668 cycle_B: 0.973 idt_B: 0.191 \n",
            "End of epoch 169 / 200 \t Time Taken: 107 sec\n",
            "learning rate = 0.0000614\n",
            "(epoch: 170, iters: 100, time: 0.572, data: 0.181) D_A: 0.095 G_A: 1.169 cycle_A: 0.888 idt_A: 0.435 D_B: 0.118 G_B: 0.589 cycle_B: 1.137 idt_B: 0.255 \n",
            "(epoch: 170, iters: 200, time: 2.331, data: 0.002) D_A: 0.100 G_A: 0.890 cycle_A: 0.632 idt_A: 0.432 D_B: 0.080 G_B: 0.988 cycle_B: 0.936 idt_B: 0.214 \n",
            "saving the model at the end of epoch 170, iters 34000\n",
            "End of epoch 170 / 200 \t Time Taken: 110 sec\n",
            "learning rate = 0.0000594\n",
            "(epoch: 171, iters: 100, time: 0.575, data: 0.210) D_A: 0.095 G_A: 0.528 cycle_A: 0.850 idt_A: 0.311 D_B: 0.226 G_B: 0.503 cycle_B: 1.165 idt_B: 0.292 \n",
            "(epoch: 171, iters: 200, time: 0.573, data: 0.001) D_A: 0.103 G_A: 0.955 cycle_A: 0.794 idt_A: 0.292 D_B: 0.170 G_B: 0.437 cycle_B: 0.883 idt_B: 0.177 \n",
            "End of epoch 171 / 200 \t Time Taken: 107 sec\n",
            "learning rate = 0.0000574\n",
            "(epoch: 172, iters: 100, time: 0.574, data: 0.180) D_A: 0.129 G_A: 0.350 cycle_A: 0.835 idt_A: 0.309 D_B: 0.205 G_B: 1.320 cycle_B: 0.804 idt_B: 0.281 \n",
            "(epoch: 172, iters: 200, time: 2.234, data: 0.002) D_A: 0.057 G_A: 0.653 cycle_A: 1.320 idt_A: 0.293 D_B: 0.153 G_B: 0.642 cycle_B: 0.778 idt_B: 0.432 \n",
            "End of epoch 172 / 200 \t Time Taken: 109 sec\n",
            "learning rate = 0.0000554\n",
            "(epoch: 173, iters: 100, time: 0.575, data: 0.155) D_A: 0.044 G_A: 0.775 cycle_A: 0.780 idt_A: 0.259 D_B: 0.067 G_B: 0.660 cycle_B: 0.798 idt_B: 0.245 \n",
            "(epoch: 173, iters: 200, time: 0.577, data: 0.001) D_A: 0.036 G_A: 0.557 cycle_A: 1.079 idt_A: 0.267 D_B: 0.099 G_B: 0.473 cycle_B: 0.823 idt_B: 0.265 \n",
            "End of epoch 173 / 200 \t Time Taken: 107 sec\n",
            "learning rate = 0.0000535\n",
            "(epoch: 174, iters: 100, time: 0.575, data: 0.174) D_A: 0.068 G_A: 0.758 cycle_A: 0.935 idt_A: 0.224 D_B: 0.284 G_B: 0.365 cycle_B: 0.669 idt_B: 0.660 \n",
            "(epoch: 174, iters: 200, time: 2.284, data: 0.001) D_A: 0.094 G_A: 0.460 cycle_A: 0.803 idt_A: 0.265 D_B: 0.107 G_B: 0.730 cycle_B: 0.787 idt_B: 0.193 \n",
            "End of epoch 174 / 200 \t Time Taken: 109 sec\n",
            "learning rate = 0.0000515\n",
            "(epoch: 175, iters: 100, time: 0.577, data: 0.177) D_A: 0.109 G_A: 1.295 cycle_A: 1.093 idt_A: 0.287 D_B: 0.108 G_B: 0.429 cycle_B: 0.921 idt_B: 0.208 \n",
            "(epoch: 175, iters: 200, time: 0.575, data: 0.001) D_A: 0.103 G_A: 0.399 cycle_A: 0.796 idt_A: 0.309 D_B: 0.054 G_B: 0.831 cycle_B: 0.850 idt_B: 0.225 \n",
            "saving the latest model (epoch 175, total_iters 35000)\n",
            "saving the model at the end of epoch 175, iters 35000\n",
            "End of epoch 175 / 200 \t Time Taken: 111 sec\n",
            "learning rate = 0.0000495\n",
            "(epoch: 176, iters: 100, time: 0.571, data: 0.206) D_A: 0.099 G_A: 0.408 cycle_A: 0.685 idt_A: 0.246 D_B: 0.046 G_B: 0.430 cycle_B: 0.807 idt_B: 0.191 \n",
            "(epoch: 176, iters: 200, time: 2.299, data: 0.001) D_A: 0.037 G_A: 0.980 cycle_A: 0.889 idt_A: 0.563 D_B: 0.043 G_B: 0.763 cycle_B: 0.877 idt_B: 0.289 \n",
            "End of epoch 176 / 200 \t Time Taken: 109 sec\n",
            "learning rate = 0.0000475\n",
            "(epoch: 177, iters: 100, time: 0.575, data: 0.172) D_A: 0.058 G_A: 0.951 cycle_A: 1.012 idt_A: 0.474 D_B: 0.207 G_B: 0.286 cycle_B: 1.001 idt_B: 0.339 \n",
            "(epoch: 177, iters: 200, time: 0.576, data: 0.001) D_A: 0.075 G_A: 0.511 cycle_A: 0.961 idt_A: 0.239 D_B: 0.129 G_B: 0.337 cycle_B: 1.051 idt_B: 0.215 \n",
            "End of epoch 177 / 200 \t Time Taken: 107 sec\n",
            "learning rate = 0.0000455\n",
            "(epoch: 178, iters: 100, time: 0.573, data: 0.173) D_A: 0.139 G_A: 0.321 cycle_A: 0.869 idt_A: 0.314 D_B: 0.129 G_B: 0.739 cycle_B: 0.961 idt_B: 0.271 \n",
            "(epoch: 178, iters: 200, time: 2.314, data: 0.001) D_A: 0.096 G_A: 0.960 cycle_A: 0.832 idt_A: 0.330 D_B: 0.197 G_B: 0.709 cycle_B: 0.876 idt_B: 0.306 \n",
            "End of epoch 178 / 200 \t Time Taken: 109 sec\n",
            "learning rate = 0.0000436\n",
            "(epoch: 179, iters: 100, time: 0.576, data: 0.165) D_A: 0.034 G_A: 0.724 cycle_A: 0.761 idt_A: 0.284 D_B: 0.230 G_B: 0.484 cycle_B: 0.762 idt_B: 0.203 \n",
            "(epoch: 179, iters: 200, time: 0.573, data: 0.001) D_A: 0.073 G_A: 0.457 cycle_A: 0.746 idt_A: 0.252 D_B: 0.140 G_B: 0.890 cycle_B: 0.799 idt_B: 0.200 \n",
            "End of epoch 179 / 200 \t Time Taken: 107 sec\n",
            "learning rate = 0.0000416\n",
            "(epoch: 180, iters: 100, time: 0.576, data: 0.160) D_A: 0.065 G_A: 1.122 cycle_A: 0.819 idt_A: 0.324 D_B: 0.097 G_B: 0.620 cycle_B: 0.756 idt_B: 0.227 \n",
            "(epoch: 180, iters: 200, time: 2.430, data: 0.002) D_A: 0.103 G_A: 0.582 cycle_A: 0.678 idt_A: 0.191 D_B: 0.145 G_B: 0.589 cycle_B: 0.567 idt_B: 0.303 \n",
            "saving the model at the end of epoch 180, iters 36000\n",
            "End of epoch 180 / 200 \t Time Taken: 110 sec\n",
            "learning rate = 0.0000396\n",
            "(epoch: 181, iters: 100, time: 0.576, data: 0.180) D_A: 0.047 G_A: 0.901 cycle_A: 0.984 idt_A: 0.242 D_B: 0.121 G_B: 0.583 cycle_B: 0.786 idt_B: 0.342 \n",
            "(epoch: 181, iters: 200, time: 0.576, data: 0.001) D_A: 0.053 G_A: 0.671 cycle_A: 1.120 idt_A: 0.329 D_B: 0.156 G_B: 0.627 cycle_B: 0.868 idt_B: 0.357 \n",
            "End of epoch 181 / 200 \t Time Taken: 107 sec\n",
            "learning rate = 0.0000376\n",
            "(epoch: 182, iters: 100, time: 0.572, data: 0.175) D_A: 0.162 G_A: 0.324 cycle_A: 0.668 idt_A: 0.394 D_B: 0.135 G_B: 0.464 cycle_B: 1.078 idt_B: 0.228 \n",
            "(epoch: 182, iters: 200, time: 2.285, data: 0.001) D_A: 0.167 G_A: 0.911 cycle_A: 0.812 idt_A: 0.288 D_B: 0.105 G_B: 1.082 cycle_B: 0.735 idt_B: 0.257 \n",
            "End of epoch 182 / 200 \t Time Taken: 109 sec\n",
            "learning rate = 0.0000356\n",
            "(epoch: 183, iters: 100, time: 0.579, data: 0.179) D_A: 0.031 G_A: 0.715 cycle_A: 0.931 idt_A: 0.248 D_B: 0.137 G_B: 0.657 cycle_B: 0.641 idt_B: 0.313 \n",
            "(epoch: 183, iters: 200, time: 0.573, data: 0.001) D_A: 0.123 G_A: 0.868 cycle_A: 0.685 idt_A: 0.252 D_B: 0.177 G_B: 0.380 cycle_B: 0.702 idt_B: 0.280 \n",
            "End of epoch 183 / 200 \t Time Taken: 107 sec\n",
            "learning rate = 0.0000337\n",
            "(epoch: 184, iters: 100, time: 0.575, data: 0.166) D_A: 0.057 G_A: 0.822 cycle_A: 0.938 idt_A: 0.344 D_B: 0.159 G_B: 0.577 cycle_B: 1.206 idt_B: 0.237 \n",
            "(epoch: 184, iters: 200, time: 2.382, data: 0.001) D_A: 0.100 G_A: 0.786 cycle_A: 0.750 idt_A: 0.229 D_B: 0.070 G_B: 0.528 cycle_B: 0.772 idt_B: 0.304 \n",
            "End of epoch 184 / 200 \t Time Taken: 109 sec\n",
            "learning rate = 0.0000317\n",
            "(epoch: 185, iters: 100, time: 0.577, data: 0.181) D_A: 0.113 G_A: 0.579 cycle_A: 0.759 idt_A: 0.248 D_B: 0.071 G_B: 0.315 cycle_B: 0.767 idt_B: 0.264 \n",
            "(epoch: 185, iters: 200, time: 0.571, data: 0.001) D_A: 0.082 G_A: 0.554 cycle_A: 0.831 idt_A: 0.280 D_B: 0.151 G_B: 0.549 cycle_B: 0.903 idt_B: 0.205 \n",
            "saving the model at the end of epoch 185, iters 37000\n",
            "End of epoch 185 / 200 \t Time Taken: 108 sec\n",
            "learning rate = 0.0000297\n",
            "(epoch: 186, iters: 100, time: 0.574, data: 0.176) D_A: 0.032 G_A: 0.643 cycle_A: 0.560 idt_A: 0.358 D_B: 0.214 G_B: 0.478 cycle_B: 1.009 idt_B: 0.174 \n",
            "(epoch: 186, iters: 200, time: 2.342, data: 0.001) D_A: 0.056 G_A: 0.770 cycle_A: 1.010 idt_A: 0.252 D_B: 0.215 G_B: 0.799 cycle_B: 0.701 idt_B: 0.310 \n",
            "End of epoch 186 / 200 \t Time Taken: 109 sec\n",
            "learning rate = 0.0000277\n",
            "(epoch: 187, iters: 100, time: 0.575, data: 0.227) D_A: 0.124 G_A: 0.775 cycle_A: 0.601 idt_A: 0.334 D_B: 0.109 G_B: 1.134 cycle_B: 0.790 idt_B: 0.176 \n",
            "(epoch: 187, iters: 200, time: 0.572, data: 0.001) D_A: 0.138 G_A: 0.747 cycle_A: 0.636 idt_A: 0.508 D_B: 0.100 G_B: 0.646 cycle_B: 1.409 idt_B: 0.190 \n",
            "End of epoch 187 / 200 \t Time Taken: 107 sec\n",
            "learning rate = 0.0000257\n",
            "(epoch: 188, iters: 100, time: 0.571, data: 0.173) D_A: 0.130 G_A: 0.491 cycle_A: 1.048 idt_A: 0.345 D_B: 0.103 G_B: 0.618 cycle_B: 0.768 idt_B: 0.345 \n",
            "(epoch: 188, iters: 200, time: 2.433, data: 0.001) D_A: 0.067 G_A: 0.570 cycle_A: 0.851 idt_A: 0.421 D_B: 0.071 G_B: 0.458 cycle_B: 0.890 idt_B: 0.266 \n",
            "End of epoch 188 / 200 \t Time Taken: 109 sec\n",
            "learning rate = 0.0000238\n",
            "(epoch: 189, iters: 100, time: 0.573, data: 0.167) D_A: 0.066 G_A: 0.820 cycle_A: 0.695 idt_A: 0.349 D_B: 0.215 G_B: 0.289 cycle_B: 0.557 idt_B: 0.209 \n",
            "(epoch: 189, iters: 200, time: 0.575, data: 0.001) D_A: 0.085 G_A: 0.582 cycle_A: 1.010 idt_A: 0.189 D_B: 0.105 G_B: 0.796 cycle_B: 0.682 idt_B: 0.394 \n",
            "End of epoch 189 / 200 \t Time Taken: 107 sec\n",
            "learning rate = 0.0000218\n",
            "(epoch: 190, iters: 100, time: 0.573, data: 0.164) D_A: 0.048 G_A: 0.735 cycle_A: 0.644 idt_A: 0.258 D_B: 0.148 G_B: 0.284 cycle_B: 0.738 idt_B: 0.153 \n",
            "(epoch: 190, iters: 200, time: 2.473, data: 0.001) D_A: 0.048 G_A: 0.700 cycle_A: 1.038 idt_A: 0.277 D_B: 0.075 G_B: 0.535 cycle_B: 0.703 idt_B: 0.339 \n",
            "saving the model at the end of epoch 190, iters 38000\n",
            "End of epoch 190 / 200 \t Time Taken: 110 sec\n",
            "learning rate = 0.0000198\n",
            "(epoch: 191, iters: 100, time: 0.574, data: 0.170) D_A: 0.069 G_A: 0.500 cycle_A: 0.514 idt_A: 0.262 D_B: 0.127 G_B: 0.549 cycle_B: 0.879 idt_B: 0.167 \n",
            "(epoch: 191, iters: 200, time: 0.575, data: 0.001) D_A: 0.104 G_A: 0.548 cycle_A: 0.815 idt_A: 0.397 D_B: 0.164 G_B: 0.534 cycle_B: 0.775 idt_B: 0.249 \n",
            "End of epoch 191 / 200 \t Time Taken: 107 sec\n",
            "learning rate = 0.0000178\n",
            "(epoch: 192, iters: 100, time: 0.574, data: 0.203) D_A: 0.057 G_A: 0.788 cycle_A: 0.994 idt_A: 0.219 D_B: 0.105 G_B: 0.436 cycle_B: 0.641 idt_B: 0.256 \n",
            "(epoch: 192, iters: 200, time: 2.425, data: 0.001) D_A: 0.115 G_A: 0.761 cycle_A: 0.631 idt_A: 0.283 D_B: 0.234 G_B: 0.492 cycle_B: 0.962 idt_B: 0.149 \n",
            "End of epoch 192 / 200 \t Time Taken: 109 sec\n",
            "learning rate = 0.0000158\n",
            "(epoch: 193, iters: 100, time: 0.577, data: 0.202) D_A: 0.099 G_A: 0.476 cycle_A: 0.633 idt_A: 0.242 D_B: 0.120 G_B: 0.649 cycle_B: 0.618 idt_B: 0.213 \n",
            "(epoch: 193, iters: 200, time: 0.576, data: 0.001) D_A: 0.083 G_A: 0.834 cycle_A: 0.984 idt_A: 0.285 D_B: 0.130 G_B: 0.439 cycle_B: 0.658 idt_B: 0.260 \n",
            "End of epoch 193 / 200 \t Time Taken: 107 sec\n",
            "learning rate = 0.0000139\n",
            "(epoch: 194, iters: 100, time: 0.575, data: 0.170) D_A: 0.067 G_A: 0.464 cycle_A: 0.879 idt_A: 0.253 D_B: 0.180 G_B: 0.343 cycle_B: 0.703 idt_B: 0.293 \n",
            "(epoch: 194, iters: 200, time: 2.432, data: 0.001) D_A: 0.042 G_A: 0.761 cycle_A: 0.808 idt_A: 0.335 D_B: 0.112 G_B: 0.538 cycle_B: 0.956 idt_B: 0.276 \n",
            "End of epoch 194 / 200 \t Time Taken: 109 sec\n",
            "learning rate = 0.0000119\n",
            "(epoch: 195, iters: 100, time: 0.572, data: 0.197) D_A: 0.074 G_A: 0.662 cycle_A: 0.560 idt_A: 0.272 D_B: 0.046 G_B: 0.753 cycle_B: 0.709 idt_B: 0.149 \n",
            "(epoch: 195, iters: 200, time: 0.573, data: 0.002) D_A: 0.084 G_A: 0.551 cycle_A: 0.928 idt_A: 0.298 D_B: 0.074 G_B: 0.643 cycle_B: 0.905 idt_B: 0.257 \n",
            "saving the model at the end of epoch 195, iters 39000\n",
            "End of epoch 195 / 200 \t Time Taken: 108 sec\n",
            "learning rate = 0.0000099\n",
            "(epoch: 196, iters: 100, time: 0.575, data: 0.188) D_A: 0.083 G_A: 0.613 cycle_A: 0.825 idt_A: 0.281 D_B: 0.168 G_B: 0.393 cycle_B: 0.881 idt_B: 0.235 \n",
            "(epoch: 196, iters: 200, time: 2.592, data: 0.001) D_A: 0.059 G_A: 0.651 cycle_A: 0.782 idt_A: 0.254 D_B: 0.102 G_B: 0.461 cycle_B: 0.670 idt_B: 0.235 \n",
            "End of epoch 196 / 200 \t Time Taken: 109 sec\n",
            "learning rate = 0.0000079\n",
            "(epoch: 197, iters: 100, time: 0.578, data: 0.209) D_A: 0.071 G_A: 1.124 cycle_A: 0.887 idt_A: 0.276 D_B: 0.098 G_B: 0.769 cycle_B: 0.778 idt_B: 0.307 \n",
            "(epoch: 197, iters: 200, time: 0.574, data: 0.001) D_A: 0.069 G_A: 0.704 cycle_A: 0.879 idt_A: 0.251 D_B: 0.112 G_B: 0.305 cycle_B: 0.664 idt_B: 0.271 \n",
            "End of epoch 197 / 200 \t Time Taken: 107 sec\n",
            "learning rate = 0.0000059\n",
            "(epoch: 198, iters: 100, time: 0.577, data: 0.169) D_A: 0.079 G_A: 0.450 cycle_A: 0.764 idt_A: 0.250 D_B: 0.156 G_B: 0.500 cycle_B: 0.717 idt_B: 0.219 \n",
            "(epoch: 198, iters: 200, time: 2.576, data: 0.001) D_A: 0.036 G_A: 0.254 cycle_A: 0.751 idt_A: 0.305 D_B: 0.209 G_B: 0.310 cycle_B: 0.631 idt_B: 0.211 \n",
            "End of epoch 198 / 200 \t Time Taken: 109 sec\n",
            "learning rate = 0.0000040\n",
            "(epoch: 199, iters: 100, time: 0.575, data: 0.191) D_A: 0.118 G_A: 0.340 cycle_A: 0.688 idt_A: 0.275 D_B: 0.136 G_B: 0.557 cycle_B: 0.720 idt_B: 0.216 \n",
            "(epoch: 199, iters: 200, time: 0.573, data: 0.001) D_A: 0.156 G_A: 0.396 cycle_A: 0.877 idt_A: 0.289 D_B: 0.246 G_B: 0.530 cycle_B: 0.790 idt_B: 0.240 \n",
            "End of epoch 199 / 200 \t Time Taken: 107 sec\n",
            "learning rate = 0.0000020\n",
            "(epoch: 200, iters: 100, time: 0.574, data: 0.180) D_A: 0.109 G_A: 0.877 cycle_A: 0.980 idt_A: 0.262 D_B: 0.103 G_B: 0.569 cycle_B: 0.896 idt_B: 0.285 \n",
            "(epoch: 200, iters: 200, time: 2.596, data: 0.001) D_A: 0.052 G_A: 0.765 cycle_A: 0.500 idt_A: 0.219 D_B: 0.083 G_B: 0.570 cycle_B: 0.791 idt_B: 0.195 \n",
            "saving the latest model (epoch 200, total_iters 40000)\n",
            "saving the model at the end of epoch 200, iters 40000\n",
            "End of epoch 200 / 200 \t Time Taken: 113 sec\n",
            "learning rate = 0.0000000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kh_DbCUs3U6q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp -r ./face2anime_checkpoints ../drive/My\\ Drive/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgUXhWIJdi7q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python test.py --dataroot ./datasets/face2anime_200/testA --name face2anime_pretrained --model test --no_dropout"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4TQzTPg-d7Af",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "img = plt.imread('./results/face2anime_pretrained/test_latest/images/n02381460_1010_fake.png')\n",
        "plt.imshow(img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bI1O03KoeaIf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "img = plt.imread('./results/horse2zebra_pretrained/test_latest/images/n02381460_1010_real.png')\n",
        "plt.imshow(img)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}